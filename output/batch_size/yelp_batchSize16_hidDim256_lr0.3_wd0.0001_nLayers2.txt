Training fold 1
In epoch:000|batch:0000, train_loss:0.666071, train_ap:0.1107, train_acc:0.5312, train_auc:0.3125
In epoch:000|batch:0010, train_loss:1.350845, train_ap:0.1111, train_acc:0.9375, train_auc:0.7419
In epoch:000|batch:0020, train_loss:0.972025, train_ap:0.1683, train_acc:0.8750, train_auc:0.5268
In epoch:000|batch:0030, train_loss:0.823190, train_ap:0.2049, train_acc:0.8125, train_auc:0.4744
In epoch:000|batch:0040, train_loss:0.734413, train_ap:0.1165, train_acc:0.7500, train_auc:0.3571
In epoch:000|batch:0050, train_loss:0.676206, train_ap:0.1125, train_acc:0.9375, train_auc:0.6167
In epoch:000|batch:0060, train_loss:0.654910, train_ap:0.3157, train_acc:0.7500, train_auc:0.4896
In epoch:000|batch:0070, train_loss:0.628364, train_ap:0.2211, train_acc:0.8125, train_auc:0.5256
In epoch:000|batch:0080, train_loss:0.605452, train_ap:0.4610, train_acc:0.8438, train_auc:0.6148
In epoch:000|batch:0090, train_loss:0.589975, train_ap:0.5000, train_acc:0.9062, train_auc:0.9310
In epoch:000|batch:0100, train_loss:0.578596, train_ap:0.1920, train_acc:0.9062, train_auc:0.5632
In epoch:000|batch:0110, train_loss:0.565099, train_ap:0.3160, train_acc:0.8125, train_auc:0.6987
In epoch:000|batch:0120, train_loss:0.550883, train_ap:0.1511, train_acc:0.9062, train_auc:0.5747
In epoch:000|batch:0130, train_loss:0.543314, train_ap:0.2438, train_acc:0.8438, train_auc:0.4963
In epoch:000|batch:0140, train_loss:0.536957, train_ap:0.1194, train_acc:0.9062, train_auc:0.5172
In epoch:000|batch:0150, train_loss:0.529055, train_ap:0.5381, train_acc:0.8438, train_auc:0.6074
In epoch:000|batch:0160, train_loss:0.525359, train_ap:0.2031, train_acc:0.8438, train_auc:0.5778
In epoch:000|batch:0170, train_loss:0.521669, train_ap:0.3756, train_acc:0.8750, train_auc:0.5893
In epoch:000|batch:0180, train_loss:0.515144, train_ap:0.0691, train_acc:0.9062, train_auc:0.0920
In epoch:000|batch:0190, train_loss:0.510041, train_ap:0.1247, train_acc:0.8750, train_auc:0.3929
In epoch:000|batch:0200, train_loss:0.503775, train_ap:0.1853, train_acc:0.8750, train_auc:0.6071
In epoch:000|batch:0210, train_loss:0.499680, train_ap:0.2444, train_acc:0.9062, train_auc:0.7241
In epoch:000|batch:0220, train_loss:0.493465, train_ap:0.1364, train_acc:0.9062, train_auc:0.5287
In epoch:000|batch:0230, train_loss:0.491581, train_ap:0.2651, train_acc:0.7500, train_auc:0.5052
In epoch:000|batch:0240, train_loss:0.488045, train_ap:0.4734, train_acc:0.8125, train_auc:0.5577
In epoch:000|batch:0250, train_loss:0.483667, train_ap:0.0357, train_acc:0.9688, train_auc:0.1290
In epoch:000|batch:0260, train_loss:0.478936, train_ap:0.1210, train_acc:0.9062, train_auc:0.4713
In epoch:000|batch:0270, train_loss:0.476200, train_ap:0.1025, train_acc:0.9375, train_auc:0.5000
In epoch:000|batch:0280, train_loss:0.473612, train_ap:0.2425, train_acc:0.8438, train_auc:0.5111
In epoch:000|batch:0290, train_loss:0.469804, train_ap:0.0667, train_acc:0.9688, train_auc:0.5484
In epoch:000|batch:0300, train_loss:0.470113, train_ap:0.3522, train_acc:0.6562, train_auc:0.4978
In epoch:000|batch:0320, train_loss:0.466889, train_ap:0.2335, train_acc:0.8438, train_auc:0.6222
In epoch:000|batch:0330, train_loss:0.466683, train_ap:0.3077, train_acc:0.8125, train_auc:0.6218
In epoch:000|batch:0340, train_loss:0.464139, train_ap:0.2386, train_acc:0.8750, train_auc:0.6875
In epoch:000|batch:0350, train_loss:0.460805, train_ap:0.2342, train_acc:0.8750, train_auc:0.5000
In epoch:000|batch:0360, train_loss:0.459492, train_ap:0.4726, train_acc:0.7188, train_auc:0.5894
In epoch:000|batch:0370, train_loss:0.459218, train_ap:0.2236, train_acc:0.8750, train_auc:0.5000
In epoch:000|batch:0380, train_loss:0.457660, train_ap:0.2592, train_acc:0.8438, train_auc:0.6815
In epoch:000|batch:0390, train_loss:0.455661, train_ap:0.4596, train_acc:0.8125, train_auc:0.6538
In epoch:000|batch:0400, train_loss:0.455468, train_ap:0.2209, train_acc:0.8750, train_auc:0.6696
In epoch:000|batch:0410, train_loss:0.454127, train_ap:0.2807, train_acc:0.7500, train_auc:0.5260
In epoch:000|batch:0420, train_loss:0.452332, train_ap:0.3214, train_acc:0.9062, train_auc:0.7931
In epoch:000|batch:0430, train_loss:0.448397, train_ap:0.2917, train_acc:0.9231, train_auc:0.8542
In epoch:000|batch:0000, val_loss:0.011857, val_ap:0.6200, val_acc:0.8438, val_auc:0.8741
In epoch:000|batch:0010, val_loss:0.012047, val_ap:0.3527, val_acc:0.8750, val_auc:0.7946
In epoch:000|batch:0020, val_loss:0.011325, val_ap:0.1250, val_acc:0.9688, val_auc:0.7742
In epoch:000|batch:0030, val_loss:0.012290, val_ap:0.3840, val_acc:0.8125, val_auc:0.6987
In epoch:000|batch:0040, val_loss:0.012353, val_ap:0.2730, val_acc:0.8438, val_auc:0.7037
In epoch:000|batch:0050, val_loss:0.012122, val_ap:0.2323, val_acc:0.8438, val_auc:0.5037
In epoch:000|batch:0060, val_loss:0.012513, val_ap:0.4707, val_acc:0.8125, val_auc:0.5513
In epoch:000|batch:0070, val_loss:0.012557, val_ap:0.5563, val_acc:0.7812, val_auc:0.7829
In epoch:000|batch:0080, val_loss:0.012470, val_ap:0.6042, val_acc:0.8750, val_auc:0.9375
In epoch:000|batch:0090, val_loss:0.012388, val_ap:0.4499, val_acc:0.7500, val_auc:0.7760
In epoch:000|batch:0100, val_loss:0.012621, val_ap:0.6917, val_acc:0.8750, val_auc:0.9464
In epoch:000|batch:0110, val_loss:0.012571, val_ap:0.2151, val_acc:0.8438, val_auc:0.5556
In epoch:000|batch:0120, val_loss:0.012343, val_ap:1.0000, val_acc:0.9688, val_auc:1.0000
In epoch:000|batch:0130, val_loss:0.012355, val_ap:0.4709, val_acc:0.9062, val_auc:0.7816
In epoch:000|batch:0140, val_loss:0.012461, val_ap:0.2154, val_acc:0.8438, val_auc:0.6148
In epoch:000|batch:0150, val_loss:0.012532, val_ap:0.2769, val_acc:0.8750, val_auc:0.5625
In epoch:000|batch:0160, val_loss:0.012331, val_ap:0.5636, val_acc:0.8438, val_auc:0.8963
In epoch:000|batch:0170, val_loss:0.012280, val_ap:0.2932, val_acc:0.8438, val_auc:0.5926
In epoch:000|batch:0180, val_loss:0.012286, val_ap:0.1746, val_acc:0.9062, val_auc:0.6897
In epoch:000|batch:0190, val_loss:0.012189, val_ap:0.2971, val_acc:0.9062, val_auc:0.7586
In epoch:000|batch:0200, val_loss:0.012148, val_ap:0.5425, val_acc:0.7188, val_auc:0.7440
In epoch:000|batch:0210, val_loss:0.012054, val_ap:0.7667, val_acc:0.9062, val_auc:0.9195
In epoch:000|batch:0220, val_loss:0.012161, val_ap:0.3911, val_acc:0.8125, val_auc:0.6346
In epoch:000|batch:0230, val_loss:0.012298, val_ap:0.3666, val_acc:0.7812, val_auc:0.7371
In epoch:000|batch:0240, val_loss:0.012232, val_ap:0.6937, val_acc:0.8750, val_auc:0.9018
In epoch:000|batch:0250, val_loss:0.012246, val_ap:0.7657, val_acc:0.7500, val_auc:0.9375
In epoch:000|batch:0260, val_loss:0.012220, val_ap:0.7167, val_acc:0.9062, val_auc:0.8046
In epoch:000|batch:0270, val_loss:0.012223, val_ap:0.6599, val_acc:0.7812, val_auc:0.7829
In epoch:000|batch:0280, val_loss:0.012248, val_ap:0.4334, val_acc:0.8438, val_auc:0.7407
In epoch:000|batch:0290, val_loss:0.012228, val_ap:0.6169, val_acc:0.8125, val_auc:0.8526
In epoch:000|batch:0300, val_loss:0.012232, val_ap:0.3694, val_acc:0.9062, val_auc:0.8851
In epoch:000|batch:0310, val_loss:0.012238, val_ap:0.2053, val_acc:0.8750, val_auc:0.6518
In epoch:000|batch:0320, val_loss:0.012226, val_ap:0.4832, val_acc:0.7500, val_auc:0.5885
In epoch:000|batch:0330, val_loss:0.012165, val_ap:0.3645, val_acc:0.8438, val_auc:0.7704
In epoch:000|batch:0340, val_loss:0.012163, val_ap:0.3276, val_acc:0.7812, val_auc:0.6743
In epoch:000|batch:0350, val_loss:0.012137, val_ap:0.2500, val_acc:0.9375, val_auc:0.8000
In epoch:000|batch:0360, val_loss:0.012121, val_ap:0.8417, val_acc:0.8125, val_auc:0.9615
In epoch:000|batch:0370, val_loss:0.012085, val_ap:0.2803, val_acc:0.8750, val_auc:0.7500
In epoch:000|batch:0380, val_loss:0.012112, val_ap:0.4569, val_acc:0.7500, val_auc:0.7031
In epoch:000|batch:0390, val_loss:0.012091, val_ap:0.1484, val_acc:0.9062, val_auc:0.6207
In epoch:000|batch:0400, val_loss:0.012091, val_ap:0.5380, val_acc:0.8750, val_auc:0.8571
In epoch:000|batch:0410, val_loss:0.012071, val_ap:0.2991, val_acc:0.8750, val_auc:0.7946
In epoch:000|batch:0420, val_loss:0.012122, val_ap:0.4720, val_acc:0.9062, val_auc:0.7126
In epoch:000|batch:0430, val_loss:0.012098, val_ap:0.3409, val_acc:0.9231, val_auc:0.7917
Best val_loss is: 0.0120977
In test batch:0000
In test batch:0010
In test batch:0020
In test batch:0030
In test batch:0040
In test batch:0050
In test batch:0060
In test batch:0070
In test batch:0080
In test batch:0090
In test batch:0100
In test batch:0110
In test batch:0120
In test batch:0130
In test batch:0140
In test batch:0150
In test batch:0160
In test batch:0170
In test batch:0180
In test batch:0190
In test batch:0200
In test batch:0210
In test batch:0220
In test batch:0230
In test batch:0240
In test batch:0250
In test batch:0260
In test batch:0270
In test batch:0280
In test batch:0290
In test batch:0300
In test batch:0310
In test batch:0320
In test batch:0330
In test batch:0340
In test batch:0350
In test batch:0360
In test batch:0370
In test batch:0380
In test batch:0390
In test batch:0400
In test batch:0410
In test batch:0420
In test batch:0430
In test batch:0440
In test batch:0450
In test batch:0460
In test batch:0470
In test batch:0480
In test batch:0490
In test batch:0500
In test batch:0510
In test batch:0520
In test batch:0530
In test batch:0540
In test batch:0550
In test batch:0560
In test batch:0570
Training fold 2
In epoch:000|batch:0000, train_loss:0.680516, train_ap:0.1369, train_acc:0.4688, train_auc:0.4107
In epoch:000|batch:0010, train_loss:0.952093, train_ap:0.1241, train_acc:0.6562, train_auc:0.2519
In epoch:000|batch:0020, train_loss:0.764312, train_ap:0.2826, train_acc:0.7812, train_auc:0.5371
In epoch:000|batch:0030, train_loss:0.719528, train_ap:0.2823, train_acc:0.9062, train_auc:0.5000
In epoch:000|batch:0040, train_loss:0.646649, train_ap:0.0783, train_acc:0.9062, train_auc:0.2184
In epoch:000|batch:0050, train_loss:0.617829, train_ap:0.2016, train_acc:0.8125, train_auc:0.3846
In epoch:000|batch:0060, train_loss:0.591977, train_ap:0.1325, train_acc:0.9375, train_auc:0.6833
In epoch:000|batch:0070, train_loss:0.569462, train_ap:0.2167, train_acc:0.9375, train_auc:0.6667
In epoch:000|batch:0080, train_loss:0.555357, train_ap:0.1493, train_acc:0.8750, train_auc:0.4821
In epoch:000|batch:0090, train_loss:0.539011, train_ap:0.1400, train_acc:0.9375, train_auc:0.5500
In epoch:000|batch:0100, train_loss:0.534870, train_ap:0.2483, train_acc:0.8438, train_auc:0.5926
In epoch:000|batch:0110, train_loss:0.524947, train_ap:0.0986, train_acc:0.8750, train_auc:0.3678
In epoch:000|batch:0120, train_loss:0.525899, train_ap:0.3126, train_acc:0.7500, train_auc:0.4948
In epoch:000|batch:0130, train_loss:0.519894, train_ap:0.3639, train_acc:0.8125, train_auc:0.5513
In epoch:000|batch:0140, train_loss:0.513958, train_ap:0.2340, train_acc:0.8125, train_auc:0.5256
In epoch:000|batch:0150, train_loss:0.508785, train_ap:0.2435, train_acc:0.8750, train_auc:0.5714
In epoch:000|batch:0160, train_loss:0.503931, train_ap:0.2135, train_acc:0.9062, train_auc:0.6207
In epoch:000|batch:0170, train_loss:0.500569, train_ap:0.3513, train_acc:0.7500, train_auc:0.5469
In epoch:000|batch:0180, train_loss:0.498705, train_ap:0.3428, train_acc:0.8125, train_auc:0.6410
In epoch:000|batch:0190, train_loss:0.490855, train_ap:0.3755, train_acc:0.8750, train_auc:0.5893
In epoch:000|batch:0200, train_loss:0.488377, train_ap:0.1187, train_acc:0.8750, train_auc:0.3750
In epoch:000|batch:0210, train_loss:0.487900, train_ap:0.4231, train_acc:0.9062, train_auc:0.6092
In epoch:000|batch:0220, train_loss:0.485214, train_ap:0.1134, train_acc:0.8438, train_auc:0.1926
In epoch:000|batch:0230, train_loss:0.481003, train_ap:0.1523, train_acc:0.9062, train_auc:0.4713
In epoch:000|batch:0240, train_loss:0.478480, train_ap:0.1253, train_acc:0.8438, train_auc:0.2593
In epoch:000|batch:0250, train_loss:0.475414, train_ap:0.0519, train_acc:0.9375, train_auc:0.1000
In epoch:000|batch:0260, train_loss:0.474671, train_ap:0.2272, train_acc:0.7500, train_auc:0.3438
In epoch:000|batch:0270, train_loss:0.472560, train_ap:0.2667, train_acc:0.9062, train_auc:0.5862
In epoch:000|batch:0280, train_loss:0.469906, train_ap:0.3920, train_acc:0.8438, train_auc:0.6815
In epoch:000|batch:0290, train_loss:0.467903, train_ap:0.1663, train_acc:0.8750, train_auc:0.4554
In epoch:000|batch:0300, train_loss:0.465488, train_ap:0.2337, train_acc:0.8125, train_auc:0.5962
In epoch:000|batch:0310, train_loss:0.462720, train_ap:0.2959, train_acc:0.7188, train_auc:0.4493
In epoch:000|batch:0320, train_loss:0.462431, train_ap:0.3238, train_acc:0.8125, train_auc:0.4615
In epoch:000|batch:0330, train_loss:0.461542, train_ap:0.3442, train_acc:0.7812, train_auc:0.4971
In epoch:000|batch:0340, train_loss:0.461884, train_ap:0.3146, train_acc:0.8125, train_auc:0.6667
In epoch:000|batch:0350, train_loss:0.462026, train_ap:0.2459, train_acc:0.7812, train_auc:0.5314
In epoch:000|batch:0360, train_loss:0.459794, train_ap:0.4061, train_acc:0.8750, train_auc:0.5982
In epoch:000|batch:0370, train_loss:0.458574, train_ap:0.1581, train_acc:0.8750, train_auc:0.3929
In epoch:000|batch:0380, train_loss:0.457229, train_ap:0.2424, train_acc:0.8125, train_auc:0.6090
In epoch:000|batch:0390, train_loss:0.458233, train_ap:0.2943, train_acc:0.8125, train_auc:0.6282
In epoch:000|batch:0400, train_loss:0.458198, train_ap:0.6156, train_acc:0.8750, train_auc:0.7054
In epoch:000|batch:0410, train_loss:0.457942, train_ap:0.2140, train_acc:0.7812, train_auc:0.4343
In epoch:000|batch:0420, train_loss:0.457355, train_ap:0.2004, train_acc:0.8438, train_auc:0.5630
In epoch:000|batch:0430, train_loss:0.455918, train_ap:0.2234, train_acc:0.7692, train_auc:0.4417
In epoch:000|batch:0000, val_loss:0.008027, val_ap:0.6000, val_acc:0.9375, val_auc:0.8667
In epoch:000|batch:0010, val_loss:0.011946, val_ap:0.2228, val_acc:0.8750, val_auc:0.5982
In epoch:000|batch:0020, val_loss:0.012936, val_ap:0.1083, val_acc:0.8750, val_auc:0.2857
In epoch:000|batch:0030, val_loss:0.012622, val_ap:0.1578, val_acc:0.8750, val_auc:0.5446
In epoch:000|batch:0040, val_loss:0.013467, val_ap:0.1414, val_acc:0.8438, val_auc:0.3630
In epoch:000|batch:0050, val_loss:0.013760, val_ap:0.2989, val_acc:0.7812, val_auc:0.5371
In epoch:000|batch:0060, val_loss:0.013404, val_ap:0.1736, val_acc:0.9375, val_auc:0.7667
In epoch:000|batch:0070, val_loss:0.013518, val_ap:0.3200, val_acc:0.7500, val_auc:0.3750
In epoch:000|batch:0080, val_loss:0.013488, val_ap:0.1230, val_acc:0.8438, val_auc:0.2593
In epoch:000|batch:0090, val_loss:0.013423, val_ap:0.2332, val_acc:0.8125, val_auc:0.4231
In epoch:000|batch:0100, val_loss:0.013483, val_ap:0.3345, val_acc:0.8125, val_auc:0.4038
In epoch:000|batch:0110, val_loss:0.013582, val_ap:0.1610, val_acc:0.7812, val_auc:0.2343
In epoch:000|batch:0120, val_loss:0.013572, val_ap:0.2566, val_acc:0.8750, val_auc:0.6161
In epoch:000|batch:0130, val_loss:0.013378, val_ap:0.1579, val_acc:0.8750, val_auc:0.5268
In epoch:000|batch:0140, val_loss:0.013277, val_ap:0.2547, val_acc:0.8438, val_auc:0.4593
In epoch:000|batch:0150, val_loss:0.013240, val_ap:0.1485, val_acc:0.8125, val_auc:0.2821
In epoch:000|batch:0160, val_loss:0.013300, val_ap:0.4187, val_acc:0.7188, val_auc:0.4058
In epoch:000|batch:0170, val_loss:0.013376, val_ap:0.2675, val_acc:0.7500, val_auc:0.5104
In epoch:000|batch:0180, val_loss:0.013391, val_ap:0.2034, val_acc:0.8750, val_auc:0.6429
In epoch:000|batch:0190, val_loss:0.013365, val_ap:0.1669, val_acc:0.7812, val_auc:0.2571
In epoch:000|batch:0200, val_loss:0.013193, val_ap:0.1472, val_acc:0.9062, val_auc:0.5862
In epoch:000|batch:0210, val_loss:0.013126, val_ap:0.2130, val_acc:0.8125, val_auc:0.5128
In epoch:000|batch:0220, val_loss:0.013115, val_ap:0.2415, val_acc:0.8125, val_auc:0.4551
In epoch:000|batch:0230, val_loss:0.013139, val_ap:0.1143, val_acc:0.8438, val_auc:0.1926
In epoch:000|batch:0240, val_loss:0.013113, val_ap:0.0651, val_acc:0.9062, val_auc:0.0345
In epoch:000|batch:0250, val_loss:0.013142, val_ap:0.4425, val_acc:0.8438, val_auc:0.7704
In epoch:000|batch:0260, val_loss:0.013169, val_ap:0.1205, val_acc:0.9062, val_auc:0.4483
In epoch:000|batch:0270, val_loss:0.013117, val_ap:0.1818, val_acc:0.7812, val_auc:0.3371
In epoch:000|batch:0280, val_loss:0.013130, val_ap:0.1141, val_acc:0.8438, val_auc:0.1926
In epoch:000|batch:0290, val_loss:0.013154, val_ap:0.2549, val_acc:0.7812, val_auc:0.5314
In epoch:000|batch:0300, val_loss:0.013133, val_ap:0.1699, val_acc:0.8438, val_auc:0.4889
In epoch:000|batch:0310, val_loss:0.013113, val_ap:0.2303, val_acc:0.7500, val_auc:0.3333
In epoch:000|batch:0320, val_loss:0.013101, val_ap:0.1481, val_acc:0.8750, val_auc:0.5000
In epoch:000|batch:0330, val_loss:0.013072, val_ap:0.1190, val_acc:0.9375, val_auc:0.4833
In epoch:000|batch:0340, val_loss:0.013029, val_ap:0.1276, val_acc:0.8750, val_auc:0.4018
In epoch:000|batch:0350, val_loss:0.013041, val_ap:0.1537, val_acc:0.8125, val_auc:0.2692
In epoch:000|batch:0360, val_loss:0.013037, val_ap:0.1754, val_acc:0.8125, val_auc:0.3910
In epoch:000|batch:0370, val_loss:0.013008, val_ap:0.2184, val_acc:0.8438, val_auc:0.4444
In epoch:000|batch:0380, val_loss:0.013005, val_ap:0.3024, val_acc:0.8125, val_auc:0.3654
In epoch:000|batch:0390, val_loss:0.012983, val_ap:0.2016, val_acc:0.8125, val_auc:0.4551
In epoch:000|batch:0400, val_loss:0.013019, val_ap:0.1736, val_acc:0.8750, val_auc:0.5089
In epoch:000|batch:0410, val_loss:0.012998, val_ap:0.0981, val_acc:0.9062, val_auc:0.3448
In epoch:000|batch:0420, val_loss:0.012986, val_ap:0.1822, val_acc:0.8125, val_auc:0.3718
In epoch:000|batch:0430, val_loss:0.012998, val_ap:0.1323, val_acc:0.8462, val_auc:0.2955
Best val_loss is: 0.0129985
In test batch:0000
In test batch:0010
In test batch:0020
In test batch:0030
In test batch:0040
In test batch:0050
In test batch:0060
In test batch:0070
In test batch:0080
In test batch:0090
In test batch:0100
In test batch:0110
In test batch:0120
In test batch:0130
In test batch:0140
In test batch:0150
In test batch:0160
In test batch:0170
In test batch:0180
In test batch:0190
In test batch:0200
In test batch:0210
In test batch:0220
In test batch:0230
In test batch:0240
In test batch:0250
In test batch:0260
In test batch:0270
In test batch:0280
In test batch:0290
In test batch:0300
In test batch:0310
In test batch:0320
In test batch:0330
In test batch:0340
In test batch:0350
In test batch:0360
In test batch:0370
In test batch:0380
In test batch:0390
In test batch:0400
In test batch:0410
In test batch:0420
In test batch:0430
In test batch:0440
In test batch:0450
In test batch:0460
In test batch:0470
In test batch:0480
In test batch:0490
In test batch:0500
In test batch:0510
In test batch:0520
In test batch:0530
In test batch:0540
In test batch:0550
In test batch:0560
In test batch:0570
NN out of fold AP is: 0.2491732631780072
test AUC:0.40716283051688895
test f1:0.4608277358988649
test AP:0.11821895364532437
