Training fold 1
In epoch:000|batch:0000, train_loss:0.711834, train_ap:0.1613, train_acc:0.5205, train_auc:0.4976
In epoch:000|batch:0010, train_loss:0.553997, train_ap:0.1962, train_acc:0.8467, train_auc:0.5615
In epoch:000|batch:0020, train_loss:0.492558, train_ap:0.2586, train_acc:0.8545, train_auc:0.6516
In epoch:000|batch:0000, val_loss:0.000428, val_ap:0.3562, val_acc:0.8408, val_auc:0.7246
In epoch:001|batch:0000, train_loss:0.380774, train_ap:0.2762, train_acc:0.8467, train_auc:0.6979
In epoch:001|batch:0010, train_loss:0.373414, train_ap:0.3882, train_acc:0.8594, train_auc:0.7441
In epoch:001|batch:0020, train_loss:0.373201, train_ap:0.4119, train_acc:0.8574, train_auc:0.8002
In epoch:001|batch:0000, val_loss:0.000465, val_ap:0.3855, val_acc:0.8359, val_auc:0.7597
In epoch:002|batch:0000, train_loss:0.391870, train_ap:0.3196, train_acc:0.8408, train_auc:0.7333
In epoch:002|batch:0010, train_loss:0.354235, train_ap:0.4296, train_acc:0.8672, train_auc:0.7783
In epoch:002|batch:0020, train_loss:0.351166, train_ap:0.4203, train_acc:0.8516, train_auc:0.7943
In epoch:002|batch:0000, val_loss:0.000376, val_ap:0.3789, val_acc:0.8350, val_auc:0.7645
In epoch:003|batch:0000, train_loss:0.303392, train_ap:0.4144, train_acc:0.8877, train_auc:0.8167
In epoch:003|batch:0010, train_loss:0.343666, train_ap:0.3492, train_acc:0.8887, train_auc:0.7565
In epoch:003|batch:0020, train_loss:0.342077, train_ap:0.5244, train_acc:0.8652, train_auc:0.8336
In epoch:003|batch:0000, val_loss:0.000359, val_ap:0.4812, val_acc:0.8301, val_auc:0.8331
In epoch:004|batch:0000, train_loss:0.325324, train_ap:0.4967, train_acc:0.8672, train_auc:0.8265
In epoch:004|batch:0010, train_loss:0.319453, train_ap:0.4871, train_acc:0.8828, train_auc:0.8210
In epoch:004|batch:0020, train_loss:0.322496, train_ap:0.5145, train_acc:0.8828, train_auc:0.8146
In epoch:004|batch:0000, val_loss:0.000307, val_ap:0.5619, val_acc:0.8721, val_auc:0.8487
In epoch:005|batch:0000, train_loss:0.302065, train_ap:0.5366, train_acc:0.8818, train_auc:0.8360
In epoch:005|batch:0010, train_loss:0.307524, train_ap:0.5647, train_acc:0.8604, train_auc:0.8351
In epoch:005|batch:0020, train_loss:0.312819, train_ap:0.5361, train_acc:0.8896, train_auc:0.8444
In epoch:005|batch:0000, val_loss:0.000342, val_ap:0.4961, val_acc:0.8535, val_auc:0.8059
In epoch:006|batch:0000, train_loss:0.281961, train_ap:0.5579, train_acc:0.8838, train_auc:0.8689
In epoch:006|batch:0010, train_loss:0.303573, train_ap:0.5877, train_acc:0.8799, train_auc:0.8347
In epoch:006|batch:0020, train_loss:0.305682, train_ap:0.5647, train_acc:0.8750, train_auc:0.8513
In epoch:006|batch:0000, val_loss:0.000360, val_ap:0.6298, val_acc:0.8613, val_auc:0.8672
In epoch:007|batch:0000, train_loss:0.286413, train_ap:0.6103, train_acc:0.8770, train_auc:0.8593
In epoch:007|batch:0010, train_loss:0.292913, train_ap:0.5763, train_acc:0.8672, train_auc:0.8505
In epoch:007|batch:0020, train_loss:0.294669, train_ap:0.6144, train_acc:0.8877, train_auc:0.8682
In epoch:007|batch:0000, val_loss:0.000367, val_ap:0.5654, val_acc:0.8564, val_auc:0.8486
In epoch:008|batch:0000, train_loss:0.295093, train_ap:0.6417, train_acc:0.8848, train_auc:0.8616
In epoch:008|batch:0010, train_loss:0.290393, train_ap:0.4999, train_acc:0.8721, train_auc:0.8274
In epoch:008|batch:0020, train_loss:0.286897, train_ap:0.6107, train_acc:0.8828, train_auc:0.8610
In epoch:008|batch:0000, val_loss:0.000298, val_ap:0.6229, val_acc:0.8838, val_auc:0.8601
In epoch:009|batch:0000, train_loss:0.285243, train_ap:0.6074, train_acc:0.8994, train_auc:0.8478
In epoch:009|batch:0010, train_loss:0.286217, train_ap:0.6277, train_acc:0.8799, train_auc:0.8719
In epoch:009|batch:0020, train_loss:0.281536, train_ap:0.6932, train_acc:0.9014, train_auc:0.8963
In epoch:009|batch:0000, val_loss:0.000270, val_ap:0.6476, val_acc:0.9014, val_auc:0.8824
In epoch:010|batch:0000, train_loss:0.240617, train_ap:0.6682, train_acc:0.8994, train_auc:0.9128
In epoch:010|batch:0010, train_loss:0.276112, train_ap:0.6305, train_acc:0.8750, train_auc:0.8784
In epoch:010|batch:0020, train_loss:0.270355, train_ap:0.6885, train_acc:0.9111, train_auc:0.9061
In epoch:010|batch:0000, val_loss:0.000276, val_ap:0.6482, val_acc:0.8721, val_auc:0.8874
In epoch:011|batch:0000, train_loss:0.243719, train_ap:0.6913, train_acc:0.9102, train_auc:0.8993
In epoch:011|batch:0010, train_loss:0.267709, train_ap:0.6029, train_acc:0.8789, train_auc:0.8594
In epoch:011|batch:0020, train_loss:0.265303, train_ap:0.7012, train_acc:0.9004, train_auc:0.9104
In epoch:011|batch:0000, val_loss:0.000313, val_ap:0.6202, val_acc:0.8525, val_auc:0.8628
In epoch:012|batch:0000, train_loss:0.293979, train_ap:0.6596, train_acc:0.8799, train_auc:0.8754
In epoch:012|batch:0010, train_loss:0.260318, train_ap:0.6465, train_acc:0.8877, train_auc:0.9052
In epoch:012|batch:0020, train_loss:0.263498, train_ap:0.5885, train_acc:0.8779, train_auc:0.8587
In epoch:012|batch:0000, val_loss:0.000298, val_ap:0.6574, val_acc:0.8740, val_auc:0.8614
In epoch:013|batch:0000, train_loss:0.263513, train_ap:0.6328, train_acc:0.8984, train_auc:0.8758
In epoch:013|batch:0010, train_loss:0.258908, train_ap:0.6660, train_acc:0.9180, train_auc:0.9017
In epoch:013|batch:0020, train_loss:0.264217, train_ap:0.6615, train_acc:0.8955, train_auc:0.8859
In epoch:013|batch:0000, val_loss:0.000246, val_ap:0.7065, val_acc:0.8984, val_auc:0.9107
In epoch:014|batch:0000, train_loss:0.237659, train_ap:0.7134, train_acc:0.9082, train_auc:0.9115
In epoch:014|batch:0010, train_loss:0.250679, train_ap:0.7100, train_acc:0.8809, train_auc:0.9061
In epoch:014|batch:0020, train_loss:0.254199, train_ap:0.6041, train_acc:0.8887, train_auc:0.8755
In epoch:014|batch:0000, val_loss:0.000281, val_ap:0.6864, val_acc:0.8779, val_auc:0.8811
Best val_loss is: 0.0002928
In test batch:0000
In test batch:0010
Training fold 2
In epoch:000|batch:0000, train_loss:0.804442, train_ap:0.1382, train_acc:0.4062, train_auc:0.5075
In epoch:000|batch:0010, train_loss:0.535146, train_ap:0.1773, train_acc:0.8584, train_auc:0.5546
In epoch:000|batch:0020, train_loss:0.498960, train_ap:0.1753, train_acc:0.8721, train_auc:0.5687
In epoch:000|batch:0000, val_loss:0.000538, val_ap:0.2276, val_acc:0.8633, val_auc:0.6195
In epoch:001|batch:0000, train_loss:0.415188, train_ap:0.1758, train_acc:0.8574, train_auc:0.5655
In epoch:001|batch:0010, train_loss:0.401022, train_ap:0.2383, train_acc:0.8447, train_auc:0.6724
In epoch:001|batch:0020, train_loss:0.390949, train_ap:0.3911, train_acc:0.8340, train_auc:0.7482
In epoch:001|batch:0000, val_loss:0.000415, val_ap:0.2713, val_acc:0.8730, val_auc:0.7513
In epoch:002|batch:0000, train_loss:0.343398, train_ap:0.3632, train_acc:0.8633, train_auc:0.7670
In epoch:002|batch:0010, train_loss:0.351186, train_ap:0.3794, train_acc:0.8955, train_auc:0.7809
In epoch:002|batch:0020, train_loss:0.350388, train_ap:0.4108, train_acc:0.8564, train_auc:0.7683
In epoch:002|batch:0000, val_loss:0.000329, val_ap:0.5434, val_acc:0.8672, val_auc:0.8166
In epoch:003|batch:0000, train_loss:0.326322, train_ap:0.4309, train_acc:0.8643, train_auc:0.8108
In epoch:003|batch:0010, train_loss:0.328431, train_ap:0.4720, train_acc:0.8623, train_auc:0.7836
In epoch:003|batch:0020, train_loss:0.325525, train_ap:0.4618, train_acc:0.8867, train_auc:0.8161
In epoch:003|batch:0000, val_loss:0.000388, val_ap:0.4684, val_acc:0.8535, val_auc:0.7875
In epoch:004|batch:0000, train_loss:0.303824, train_ap:0.4910, train_acc:0.8877, train_auc:0.8220
In epoch:004|batch:0010, train_loss:0.319759, train_ap:0.4645, train_acc:0.8711, train_auc:0.8168
In epoch:004|batch:0020, train_loss:0.320877, train_ap:0.4995, train_acc:0.8643, train_auc:0.8423
In epoch:004|batch:0000, val_loss:0.000283, val_ap:0.5525, val_acc:0.8848, val_auc:0.8501
In epoch:005|batch:0000, train_loss:0.297624, train_ap:0.6399, train_acc:0.8838, train_auc:0.8598
In epoch:005|batch:0010, train_loss:0.311642, train_ap:0.5292, train_acc:0.8867, train_auc:0.8413
In epoch:005|batch:0020, train_loss:0.311272, train_ap:0.5093, train_acc:0.8633, train_auc:0.8208
In epoch:005|batch:0000, val_loss:0.000323, val_ap:0.5054, val_acc:0.8682, val_auc:0.8256
In epoch:006|batch:0000, train_loss:0.313414, train_ap:0.4664, train_acc:0.8740, train_auc:0.8112
In epoch:006|batch:0010, train_loss:0.301200, train_ap:0.6019, train_acc:0.8848, train_auc:0.8460
In epoch:006|batch:0020, train_loss:0.302348, train_ap:0.5643, train_acc:0.8721, train_auc:0.8555
In epoch:006|batch:0000, val_loss:0.000315, val_ap:0.5121, val_acc:0.8730, val_auc:0.8241
In epoch:007|batch:0000, train_loss:0.297191, train_ap:0.6649, train_acc:0.8936, train_auc:0.8602
In epoch:007|batch:0010, train_loss:0.305628, train_ap:0.5485, train_acc:0.8643, train_auc:0.8295
In epoch:007|batch:0020, train_loss:0.303379, train_ap:0.5076, train_acc:0.8691, train_auc:0.8054
In epoch:007|batch:0000, val_loss:0.000299, val_ap:0.5158, val_acc:0.8691, val_auc:0.8444
In epoch:008|batch:0000, train_loss:0.273746, train_ap:0.5936, train_acc:0.8955, train_auc:0.8667
In epoch:008|batch:0010, train_loss:0.298713, train_ap:0.5736, train_acc:0.8730, train_auc:0.8520
In epoch:008|batch:0020, train_loss:0.301728, train_ap:0.5612, train_acc:0.8691, train_auc:0.8499
In epoch:008|batch:0000, val_loss:0.000317, val_ap:0.5707, val_acc:0.8809, val_auc:0.8321
In epoch:009|batch:0000, train_loss:0.300009, train_ap:0.5759, train_acc:0.8896, train_auc:0.8411
In epoch:009|batch:0010, train_loss:0.298751, train_ap:0.5508, train_acc:0.8799, train_auc:0.8484
In epoch:009|batch:0020, train_loss:0.297009, train_ap:0.5520, train_acc:0.8906, train_auc:0.8520
In epoch:009|batch:0000, val_loss:0.000284, val_ap:0.6051, val_acc:0.8838, val_auc:0.8623
In epoch:010|batch:0000, train_loss:0.309697, train_ap:0.5037, train_acc:0.8691, train_auc:0.8438
In epoch:010|batch:0010, train_loss:0.290078, train_ap:0.5788, train_acc:0.8779, train_auc:0.8561
In epoch:010|batch:0020, train_loss:0.289182, train_ap:0.5720, train_acc:0.8916, train_auc:0.8545
In epoch:010|batch:0000, val_loss:0.000308, val_ap:0.5907, val_acc:0.8818, val_auc:0.8317
In epoch:011|batch:0000, train_loss:0.290701, train_ap:0.5999, train_acc:0.8740, train_auc:0.8678
In epoch:011|batch:0010, train_loss:0.291659, train_ap:0.6044, train_acc:0.8848, train_auc:0.8819
In epoch:011|batch:0020, train_loss:0.285473, train_ap:0.5873, train_acc:0.8799, train_auc:0.8648
In epoch:011|batch:0000, val_loss:0.000300, val_ap:0.5690, val_acc:0.8828, val_auc:0.8285
In epoch:012|batch:0000, train_loss:0.282537, train_ap:0.6228, train_acc:0.8828, train_auc:0.8760
In epoch:012|batch:0010, train_loss:0.277319, train_ap:0.6315, train_acc:0.9014, train_auc:0.8792
In epoch:012|batch:0020, train_loss:0.282064, train_ap:0.6399, train_acc:0.8867, train_auc:0.8743
In epoch:012|batch:0000, val_loss:0.000291, val_ap:0.5712, val_acc:0.8818, val_auc:0.8475
In epoch:013|batch:0000, train_loss:0.254873, train_ap:0.6295, train_acc:0.9014, train_auc:0.8863
In epoch:013|batch:0010, train_loss:0.279847, train_ap:0.6134, train_acc:0.8750, train_auc:0.8671
In epoch:013|batch:0020, train_loss:0.282056, train_ap:0.5204, train_acc:0.8828, train_auc:0.8327
In epoch:013|batch:0000, val_loss:0.000299, val_ap:0.4782, val_acc:0.8857, val_auc:0.8168
In epoch:014|batch:0000, train_loss:0.245279, train_ap:0.6769, train_acc:0.8945, train_auc:0.9022
In epoch:014|batch:0010, train_loss:0.278214, train_ap:0.6637, train_acc:0.8857, train_auc:0.8841
In epoch:014|batch:0020, train_loss:0.279213, train_ap:0.6114, train_acc:0.8936, train_auc:0.8685
In epoch:014|batch:0000, val_loss:0.000292, val_ap:0.6439, val_acc:0.8789, val_auc:0.8646
Best val_loss is: 0.0003107
In test batch:0000
In test batch:0010
Training fold 3
In epoch:000|batch:0000, train_loss:0.720059, train_ap:0.1448, train_acc:0.5156, train_auc:0.5524
In epoch:000|batch:0010, train_loss:0.492429, train_ap:0.2615, train_acc:0.8359, train_auc:0.6978
In epoch:000|batch:0020, train_loss:0.445113, train_ap:0.3490, train_acc:0.8652, train_auc:0.7683
In epoch:000|batch:0000, val_loss:0.000479, val_ap:0.3279, val_acc:0.8486, val_auc:0.7481
In epoch:001|batch:0000, train_loss:0.302124, train_ap:0.3483, train_acc:0.8818, train_auc:0.8032
In epoch:001|batch:0010, train_loss:0.358113, train_ap:0.4486, train_acc:0.8389, train_auc:0.7866
In epoch:001|batch:0020, train_loss:0.353487, train_ap:0.3963, train_acc:0.8643, train_auc:0.7714
In epoch:001|batch:0000, val_loss:0.000376, val_ap:0.4151, val_acc:0.8564, val_auc:0.7980
In epoch:002|batch:0000, train_loss:0.328778, train_ap:0.3567, train_acc:0.8711, train_auc:0.7770
In epoch:002|batch:0010, train_loss:0.331492, train_ap:0.5207, train_acc:0.8633, train_auc:0.8198
In epoch:002|batch:0020, train_loss:0.331494, train_ap:0.4611, train_acc:0.8633, train_auc:0.8184
In epoch:002|batch:0000, val_loss:0.000360, val_ap:0.4895, val_acc:0.8398, val_auc:0.8263
In epoch:003|batch:0000, train_loss:0.325332, train_ap:0.3842, train_acc:0.8662, train_auc:0.7981
In epoch:003|batch:0010, train_loss:0.318361, train_ap:0.5525, train_acc:0.8740, train_auc:0.8000
In epoch:003|batch:0020, train_loss:0.321363, train_ap:0.5194, train_acc:0.8701, train_auc:0.8415
In epoch:003|batch:0000, val_loss:0.000298, val_ap:0.5907, val_acc:0.8701, val_auc:0.8588
In epoch:004|batch:0000, train_loss:0.277154, train_ap:0.5045, train_acc:0.8945, train_auc:0.8364
In epoch:004|batch:0010, train_loss:0.298020, train_ap:0.5264, train_acc:0.8779, train_auc:0.8481
In epoch:004|batch:0020, train_loss:0.304865, train_ap:0.5641, train_acc:0.8877, train_auc:0.8505
In epoch:004|batch:0000, val_loss:0.000295, val_ap:0.5467, val_acc:0.8838, val_auc:0.8397
In epoch:005|batch:0000, train_loss:0.314287, train_ap:0.5796, train_acc:0.8652, train_auc:0.8600
In epoch:005|batch:0010, train_loss:0.307246, train_ap:0.5720, train_acc:0.8857, train_auc:0.8453
In epoch:005|batch:0020, train_loss:0.301521, train_ap:0.5302, train_acc:0.8818, train_auc:0.8421
In epoch:005|batch:0000, val_loss:0.000266, val_ap:0.5792, val_acc:0.8994, val_auc:0.8678
In epoch:006|batch:0000, train_loss:0.271576, train_ap:0.6284, train_acc:0.8877, train_auc:0.8890
In epoch:006|batch:0010, train_loss:0.288947, train_ap:0.5612, train_acc:0.8789, train_auc:0.8571
In epoch:006|batch:0020, train_loss:0.296340, train_ap:0.5783, train_acc:0.8721, train_auc:0.8428
In epoch:006|batch:0000, val_loss:0.000321, val_ap:0.5544, val_acc:0.8682, val_auc:0.8285
In epoch:007|batch:0000, train_loss:0.286226, train_ap:0.6096, train_acc:0.8828, train_auc:0.8653
In epoch:007|batch:0010, train_loss:0.292368, train_ap:0.5592, train_acc:0.8740, train_auc:0.8560
In epoch:007|batch:0020, train_loss:0.294217, train_ap:0.5692, train_acc:0.8867, train_auc:0.8542
In epoch:007|batch:0000, val_loss:0.000280, val_ap:0.5818, val_acc:0.8809, val_auc:0.8646
In epoch:008|batch:0000, train_loss:0.283792, train_ap:0.5809, train_acc:0.8887, train_auc:0.8554
In epoch:008|batch:0010, train_loss:0.282831, train_ap:0.5385, train_acc:0.8750, train_auc:0.8428
In epoch:008|batch:0020, train_loss:0.289427, train_ap:0.6227, train_acc:0.8887, train_auc:0.8610
In epoch:008|batch:0000, val_loss:0.000288, val_ap:0.5305, val_acc:0.8818, val_auc:0.8470
In epoch:009|batch:0000, train_loss:0.288182, train_ap:0.6269, train_acc:0.8799, train_auc:0.8684
In epoch:009|batch:0010, train_loss:0.284187, train_ap:0.6767, train_acc:0.9033, train_auc:0.8775
In epoch:009|batch:0020, train_loss:0.285096, train_ap:0.6059, train_acc:0.8809, train_auc:0.8777
In epoch:009|batch:0000, val_loss:0.000327, val_ap:0.5171, val_acc:0.8652, val_auc:0.8183
In epoch:010|batch:0000, train_loss:0.266086, train_ap:0.6339, train_acc:0.8975, train_auc:0.8806
In epoch:010|batch:0010, train_loss:0.285549, train_ap:0.6405, train_acc:0.8984, train_auc:0.8986
In epoch:010|batch:0020, train_loss:0.281252, train_ap:0.6486, train_acc:0.9062, train_auc:0.8844
In epoch:010|batch:0000, val_loss:0.000243, val_ap:0.5999, val_acc:0.9111, val_auc:0.8688
In epoch:011|batch:0000, train_loss:0.289603, train_ap:0.5971, train_acc:0.8828, train_auc:0.8636
In epoch:011|batch:0010, train_loss:0.278482, train_ap:0.6894, train_acc:0.9053, train_auc:0.8960
In epoch:011|batch:0020, train_loss:0.273536, train_ap:0.6186, train_acc:0.8975, train_auc:0.8872
In epoch:011|batch:0000, val_loss:0.000311, val_ap:0.5486, val_acc:0.8740, val_auc:0.8452
In epoch:012|batch:0000, train_loss:0.246387, train_ap:0.6125, train_acc:0.9043, train_auc:0.8878
In epoch:012|batch:0010, train_loss:0.265182, train_ap:0.6463, train_acc:0.9004, train_auc:0.8669
In epoch:012|batch:0020, train_loss:0.265685, train_ap:0.6817, train_acc:0.8838, train_auc:0.8973
In epoch:012|batch:0000, val_loss:0.000275, val_ap:0.6084, val_acc:0.8750, val_auc:0.8884
In epoch:013|batch:0000, train_loss:0.232274, train_ap:0.7415, train_acc:0.9082, train_auc:0.9201
In epoch:013|batch:0010, train_loss:0.254990, train_ap:0.6575, train_acc:0.8975, train_auc:0.8894
In epoch:013|batch:0020, train_loss:0.260412, train_ap:0.6716, train_acc:0.8877, train_auc:0.8842
In epoch:013|batch:0000, val_loss:0.000260, val_ap:0.6697, val_acc:0.8828, val_auc:0.9063
In epoch:014|batch:0000, train_loss:0.257808, train_ap:0.7001, train_acc:0.8916, train_auc:0.9087
In epoch:014|batch:0010, train_loss:0.259595, train_ap:0.6602, train_acc:0.8984, train_auc:0.8842
In epoch:014|batch:0020, train_loss:0.258156, train_ap:0.6432, train_acc:0.8955, train_auc:0.8729
In epoch:014|batch:0000, val_loss:0.000252, val_ap:0.6734, val_acc:0.8955, val_auc:0.9019
Best val_loss is: 0.0002904
In test batch:0000
In test batch:0010
Training fold 4
In epoch:000|batch:0000, train_loss:0.640670, train_ap:0.1539, train_acc:0.6396, train_auc:0.4964
In epoch:000|batch:0010, train_loss:0.475689, train_ap:0.2969, train_acc:0.8594, train_auc:0.6939
In epoch:000|batch:0020, train_loss:0.432532, train_ap:0.3626, train_acc:0.8555, train_auc:0.7591
In epoch:000|batch:0000, val_loss:0.000490, val_ap:0.3417, val_acc:0.8711, val_auc:0.7487
In epoch:001|batch:0000, train_loss:0.305897, train_ap:0.3498, train_acc:0.8760, train_auc:0.8055
In epoch:001|batch:0010, train_loss:0.354359, train_ap:0.4378, train_acc:0.8682, train_auc:0.7911
In epoch:001|batch:0020, train_loss:0.350848, train_ap:0.4439, train_acc:0.8740, train_auc:0.8203
In epoch:001|batch:0000, val_loss:0.000415, val_ap:0.4194, val_acc:0.8457, val_auc:0.7810
In epoch:002|batch:0000, train_loss:0.340477, train_ap:0.5109, train_acc:0.8613, train_auc:0.8074
In epoch:002|batch:0010, train_loss:0.325116, train_ap:0.4179, train_acc:0.8818, train_auc:0.7839
In epoch:002|batch:0020, train_loss:0.323876, train_ap:0.4998, train_acc:0.8828, train_auc:0.8230
In epoch:002|batch:0000, val_loss:0.000330, val_ap:0.4529, val_acc:0.8506, val_auc:0.8130
In epoch:003|batch:0000, train_loss:0.293025, train_ap:0.5145, train_acc:0.8877, train_auc:0.8485
In epoch:003|batch:0010, train_loss:0.308427, train_ap:0.5256, train_acc:0.8760, train_auc:0.8146
In epoch:003|batch:0020, train_loss:0.310436, train_ap:0.5334, train_acc:0.8730, train_auc:0.8165
In epoch:003|batch:0000, val_loss:0.000339, val_ap:0.5336, val_acc:0.8486, val_auc:0.8227
In epoch:004|batch:0000, train_loss:0.303788, train_ap:0.6391, train_acc:0.8809, train_auc:0.8608
In epoch:004|batch:0010, train_loss:0.306054, train_ap:0.5721, train_acc:0.8701, train_auc:0.8346
In epoch:004|batch:0020, train_loss:0.303297, train_ap:0.5558, train_acc:0.8916, train_auc:0.8558
In epoch:004|batch:0000, val_loss:0.000297, val_ap:0.5681, val_acc:0.8779, val_auc:0.8506
In epoch:005|batch:0000, train_loss:0.302327, train_ap:0.5371, train_acc:0.8838, train_auc:0.8309
In epoch:005|batch:0010, train_loss:0.288677, train_ap:0.5391, train_acc:0.8818, train_auc:0.8536
In epoch:005|batch:0020, train_loss:0.294204, train_ap:0.6300, train_acc:0.8701, train_auc:0.8521
In epoch:005|batch:0000, val_loss:0.000309, val_ap:0.5584, val_acc:0.8760, val_auc:0.8344
In epoch:006|batch:0000, train_loss:0.325119, train_ap:0.6086, train_acc:0.8818, train_auc:0.8268
In epoch:006|batch:0010, train_loss:0.297447, train_ap:0.6727, train_acc:0.8848, train_auc:0.8905
In epoch:006|batch:0020, train_loss:0.291076, train_ap:0.6515, train_acc:0.8975, train_auc:0.8687
In epoch:006|batch:0000, val_loss:0.000283, val_ap:0.5291, val_acc:0.8770, val_auc:0.8600
In epoch:007|batch:0000, train_loss:0.271980, train_ap:0.6492, train_acc:0.8867, train_auc:0.8818
In epoch:007|batch:0010, train_loss:0.279662, train_ap:0.6710, train_acc:0.8887, train_auc:0.8788
In epoch:007|batch:0020, train_loss:0.281697, train_ap:0.6156, train_acc:0.8799, train_auc:0.8823
In epoch:007|batch:0000, val_loss:0.000283, val_ap:0.5724, val_acc:0.8857, val_auc:0.8576
In epoch:008|batch:0000, train_loss:0.273801, train_ap:0.6252, train_acc:0.8926, train_auc:0.8764
In epoch:008|batch:0010, train_loss:0.269436, train_ap:0.6299, train_acc:0.8984, train_auc:0.8806
In epoch:008|batch:0020, train_loss:0.278275, train_ap:0.6132, train_acc:0.8887, train_auc:0.8403
In epoch:008|batch:0000, val_loss:0.000291, val_ap:0.5866, val_acc:0.8740, val_auc:0.8548
In epoch:009|batch:0000, train_loss:0.274238, train_ap:0.6716, train_acc:0.8848, train_auc:0.8893
In epoch:009|batch:0010, train_loss:0.270421, train_ap:0.6813, train_acc:0.8975, train_auc:0.8888
In epoch:009|batch:0020, train_loss:0.274074, train_ap:0.6158, train_acc:0.8799, train_auc:0.8620
In epoch:009|batch:0000, val_loss:0.000266, val_ap:0.6133, val_acc:0.8906, val_auc:0.8744
In epoch:010|batch:0000, train_loss:0.244771, train_ap:0.6734, train_acc:0.9072, train_auc:0.8902
In epoch:010|batch:0010, train_loss:0.265894, train_ap:0.6257, train_acc:0.8740, train_auc:0.8855
In epoch:010|batch:0020, train_loss:0.268997, train_ap:0.6868, train_acc:0.9014, train_auc:0.8837
In epoch:010|batch:0000, val_loss:0.000280, val_ap:0.6576, val_acc:0.8936, val_auc:0.8715
In epoch:011|batch:0000, train_loss:0.263510, train_ap:0.6937, train_acc:0.8906, train_auc:0.8946
In epoch:011|batch:0010, train_loss:0.261631, train_ap:0.6989, train_acc:0.8916, train_auc:0.8830
In epoch:011|batch:0020, train_loss:0.261710, train_ap:0.6989, train_acc:0.8936, train_auc:0.9004
In epoch:011|batch:0000, val_loss:0.000254, val_ap:0.6633, val_acc:0.9004, val_auc:0.8936
In epoch:012|batch:0000, train_loss:0.263275, train_ap:0.6764, train_acc:0.8936, train_auc:0.9022
In epoch:012|batch:0010, train_loss:0.266276, train_ap:0.6586, train_acc:0.8887, train_auc:0.8782
In epoch:012|batch:0020, train_loss:0.259232, train_ap:0.6400, train_acc:0.8965, train_auc:0.8942
In epoch:012|batch:0000, val_loss:0.000292, val_ap:0.5946, val_acc:0.8779, val_auc:0.8526
In epoch:013|batch:0000, train_loss:0.254918, train_ap:0.6966, train_acc:0.9023, train_auc:0.8986
In epoch:013|batch:0010, train_loss:0.254498, train_ap:0.7032, train_acc:0.9053, train_auc:0.9051
In epoch:013|batch:0020, train_loss:0.257259, train_ap:0.6996, train_acc:0.9111, train_auc:0.9182
In epoch:013|batch:0000, val_loss:0.000266, val_ap:0.6200, val_acc:0.8945, val_auc:0.8674
In epoch:014|batch:0000, train_loss:0.263774, train_ap:0.7115, train_acc:0.8945, train_auc:0.8988
In epoch:014|batch:0010, train_loss:0.252599, train_ap:0.6634, train_acc:0.8926, train_auc:0.8798
In epoch:014|batch:0020, train_loss:0.251690, train_ap:0.6356, train_acc:0.8896, train_auc:0.8835
In epoch:014|batch:0000, val_loss:0.000229, val_ap:0.6753, val_acc:0.9111, val_auc:0.9016
Best val_loss is: 0.0002908
In test batch:0000
In test batch:0010
Training fold 5
In epoch:000|batch:0000, train_loss:0.683936, train_ap:0.1631, train_acc:0.5713, train_auc:0.5609
In epoch:000|batch:0010, train_loss:0.500788, train_ap:0.2985, train_acc:0.8457, train_auc:0.6776
In epoch:000|batch:0020, train_loss:0.447407, train_ap:0.3535, train_acc:0.8340, train_auc:0.7622
In epoch:000|batch:0000, val_loss:0.000436, val_ap:0.4282, val_acc:0.8447, val_auc:0.8068
In epoch:001|batch:0000, train_loss:0.345409, train_ap:0.3407, train_acc:0.8613, train_auc:0.7759
In epoch:001|batch:0010, train_loss:0.360109, train_ap:0.3805, train_acc:0.8564, train_auc:0.7549
In epoch:001|batch:0020, train_loss:0.352515, train_ap:0.4206, train_acc:0.8564, train_auc:0.8019
In epoch:001|batch:0000, val_loss:0.000403, val_ap:0.4037, val_acc:0.8545, val_auc:0.8249
In epoch:002|batch:0000, train_loss:0.334041, train_ap:0.4793, train_acc:0.8525, train_auc:0.8272
In epoch:002|batch:0010, train_loss:0.336437, train_ap:0.4600, train_acc:0.8613, train_auc:0.7780
In epoch:002|batch:0020, train_loss:0.327248, train_ap:0.5802, train_acc:0.8926, train_auc:0.8799
In epoch:002|batch:0000, val_loss:0.000288, val_ap:0.5418, val_acc:0.8740, val_auc:0.8565
In epoch:003|batch:0000, train_loss:0.320034, train_ap:0.5397, train_acc:0.8633, train_auc:0.8347
In epoch:003|batch:0010, train_loss:0.316765, train_ap:0.5873, train_acc:0.8789, train_auc:0.8486
In epoch:003|batch:0020, train_loss:0.317479, train_ap:0.5512, train_acc:0.8828, train_auc:0.8303
In epoch:003|batch:0000, val_loss:0.000296, val_ap:0.6007, val_acc:0.8721, val_auc:0.8751
In epoch:004|batch:0000, train_loss:0.300249, train_ap:0.4934, train_acc:0.8887, train_auc:0.8157
In epoch:004|batch:0010, train_loss:0.315055, train_ap:0.5100, train_acc:0.8867, train_auc:0.8456
In epoch:004|batch:0020, train_loss:0.308494, train_ap:0.5754, train_acc:0.8994, train_auc:0.8636
In epoch:004|batch:0000, val_loss:0.000291, val_ap:0.5590, val_acc:0.8740, val_auc:0.8521
In epoch:005|batch:0000, train_loss:0.295310, train_ap:0.6134, train_acc:0.8730, train_auc:0.8717
In epoch:005|batch:0010, train_loss:0.299811, train_ap:0.6152, train_acc:0.8916, train_auc:0.8597
In epoch:005|batch:0020, train_loss:0.300031, train_ap:0.5307, train_acc:0.8701, train_auc:0.8445
In epoch:005|batch:0000, val_loss:0.000294, val_ap:0.6466, val_acc:0.8779, val_auc:0.8669
In epoch:006|batch:0000, train_loss:0.291013, train_ap:0.5223, train_acc:0.8809, train_auc:0.8451
In epoch:006|batch:0010, train_loss:0.297928, train_ap:0.5132, train_acc:0.8711, train_auc:0.8436
In epoch:006|batch:0020, train_loss:0.293770, train_ap:0.4863, train_acc:0.8838, train_auc:0.8271
In epoch:006|batch:0000, val_loss:0.000331, val_ap:0.5607, val_acc:0.8535, val_auc:0.8470
In epoch:007|batch:0000, train_loss:0.307888, train_ap:0.5696, train_acc:0.8770, train_auc:0.8410
In epoch:007|batch:0010, train_loss:0.296789, train_ap:0.5745, train_acc:0.8789, train_auc:0.8503
In epoch:007|batch:0020, train_loss:0.296385, train_ap:0.5337, train_acc:0.8740, train_auc:0.8399
In epoch:007|batch:0000, val_loss:0.000281, val_ap:0.5465, val_acc:0.8779, val_auc:0.8588
In epoch:008|batch:0000, train_loss:0.306011, train_ap:0.5838, train_acc:0.8711, train_auc:0.8536
In epoch:008|batch:0010, train_loss:0.293031, train_ap:0.6555, train_acc:0.8828, train_auc:0.8932
In epoch:008|batch:0020, train_loss:0.289366, train_ap:0.6082, train_acc:0.8760, train_auc:0.8615
In epoch:008|batch:0000, val_loss:0.000297, val_ap:0.5731, val_acc:0.8662, val_auc:0.8557
In epoch:009|batch:0000, train_loss:0.269138, train_ap:0.6009, train_acc:0.8906, train_auc:0.8803
In epoch:009|batch:0010, train_loss:0.285349, train_ap:0.6597, train_acc:0.8916, train_auc:0.8801
In epoch:009|batch:0020, train_loss:0.281687, train_ap:0.5899, train_acc:0.8760, train_auc:0.8531
In epoch:009|batch:0000, val_loss:0.000291, val_ap:0.6216, val_acc:0.8779, val_auc:0.8603
In epoch:010|batch:0000, train_loss:0.308145, train_ap:0.5652, train_acc:0.8730, train_auc:0.8504
In epoch:010|batch:0010, train_loss:0.285628, train_ap:0.5997, train_acc:0.8877, train_auc:0.8444
In epoch:010|batch:0020, train_loss:0.280121, train_ap:0.6739, train_acc:0.8887, train_auc:0.9045
In epoch:010|batch:0000, val_loss:0.000282, val_ap:0.6366, val_acc:0.8818, val_auc:0.8663
In epoch:011|batch:0000, train_loss:0.308642, train_ap:0.6154, train_acc:0.8701, train_auc:0.8595
In epoch:011|batch:0010, train_loss:0.277258, train_ap:0.6094, train_acc:0.9023, train_auc:0.8743
In epoch:011|batch:0020, train_loss:0.280434, train_ap:0.6729, train_acc:0.8906, train_auc:0.8781
In epoch:011|batch:0000, val_loss:0.000298, val_ap:0.5455, val_acc:0.8613, val_auc:0.8512
In epoch:012|batch:0000, train_loss:0.274276, train_ap:0.6278, train_acc:0.8838, train_auc:0.8879
In epoch:012|batch:0010, train_loss:0.271406, train_ap:0.6589, train_acc:0.8770, train_auc:0.8768
In epoch:012|batch:0020, train_loss:0.273843, train_ap:0.5501, train_acc:0.8867, train_auc:0.8507
In epoch:012|batch:0000, val_loss:0.000241, val_ap:0.6446, val_acc:0.9023, val_auc:0.9032
In epoch:013|batch:0000, train_loss:0.276791, train_ap:0.6694, train_acc:0.8945, train_auc:0.8826
In epoch:013|batch:0010, train_loss:0.275947, train_ap:0.6530, train_acc:0.8848, train_auc:0.8947
In epoch:013|batch:0020, train_loss:0.270918, train_ap:0.6245, train_acc:0.8838, train_auc:0.8794
In epoch:013|batch:0000, val_loss:0.000282, val_ap:0.5669, val_acc:0.8730, val_auc:0.8727
In epoch:014|batch:0000, train_loss:0.261006, train_ap:0.7098, train_acc:0.8975, train_auc:0.9038
In epoch:014|batch:0010, train_loss:0.272903, train_ap:0.6631, train_acc:0.9082, train_auc:0.8985
In epoch:014|batch:0020, train_loss:0.268902, train_ap:0.6238, train_acc:0.9023, train_auc:0.8790
In epoch:014|batch:0000, val_loss:0.000269, val_ap:0.6563, val_acc:0.8965, val_auc:0.8834
Best val_loss is: 0.0002910
In test batch:0000
In test batch:0010
NN out of fold AP is: 0.6371281320617197
test AUC:0.8769417707491318
test f1:0.7120588363492992
test AP:0.6315380619406208
