Training fold 1
In epoch:000|batch:0000, train_loss:0.666109, train_ap:0.1610, train_acc:0.5918, train_auc:0.4707
In epoch:000|batch:0010, train_loss:2.150643, train_ap:0.1087, train_acc:0.8926, train_auc:0.4756
In epoch:000|batch:0020, train_loss:1.363597, train_ap:0.1373, train_acc:0.8438, train_auc:0.4767
In epoch:000|batch:0000, val_loss:0.010664, val_ap:0.1620, val_acc:0.1504, val_auc:0.5150
In epoch:000|batch:0010, val_loss:0.010733, val_ap:0.1519, val_acc:0.1172, val_auc:0.5185
In epoch:000|batch:0020, val_loss:0.010719, val_ap:0.1232, val_acc:0.1406, val_auc:0.4265
Best val_loss is: 0.0107177
In test batch:0000
In test batch:0010
In test batch:0020
In test batch:0030
Training fold 2
In epoch:000|batch:0000, train_loss:0.643148, train_ap:0.1196, train_acc:0.6406, train_auc:0.4546
In epoch:000|batch:0010, train_loss:2.529023, train_ap:0.1107, train_acc:0.8770, train_auc:0.4439
In epoch:000|batch:0020, train_loss:1.632514, train_ap:0.1270, train_acc:0.5156, train_auc:0.4717
In epoch:000|batch:0000, val_loss:0.000805, val_ap:0.1730, val_acc:0.8828, val_auc:0.5525
In epoch:000|batch:0010, val_loss:0.000968, val_ap:0.1958, val_acc:0.8496, val_auc:0.5515
In epoch:000|batch:0020, val_loss:0.000962, val_ap:0.1824, val_acc:0.8730, val_auc:0.5604
Best val_loss is: 0.0009667
In test batch:0000
In test batch:0010
In test batch:0020
In test batch:0030
NN out of fold AP is: 0.15434705227893394
test AUC:0.5646201807684053
test f1:0.4608277358988649
test AP:0.1819159253000776
