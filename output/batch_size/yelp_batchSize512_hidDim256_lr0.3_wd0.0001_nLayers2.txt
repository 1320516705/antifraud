Training fold 1
In epoch:000|batch:0000, train_loss:0.784179, train_ap:0.1461, train_acc:0.3945, train_auc:0.5098
In epoch:000|batch:0010, train_loss:6.817540, train_ap:0.1642, train_acc:0.8516, train_auc:0.5225
In epoch:000|batch:0000, val_loss:0.001595, val_ap:0.1459, val_acc:0.8682, val_auc:0.5037
In epoch:000|batch:0010, val_loss:0.001759, val_ap:0.1383, val_acc:0.8545, val_auc:0.4446
Best val_loss is: 0.0018322
In test batch:0000
In test batch:0010
Training fold 2
In epoch:000|batch:0000, train_loss:0.610619, train_ap:0.1794, train_acc:0.6836, train_auc:0.5314
In epoch:000|batch:0010, train_loss:3.968817, train_ap:0.1706, train_acc:0.5391, train_auc:0.5371
In epoch:000|batch:0000, val_loss:0.004674, val_ap:0.1791, val_acc:0.8555, val_auc:0.5873
In epoch:000|batch:0010, val_loss:0.004644, val_ap:0.1395, val_acc:0.8779, val_auc:0.5278
Best val_loss is: 0.0049418
In test batch:0000
In test batch:0010
NN out of fold AP is: 0.14225260318130678
test AUC:0.550255181329957
test f1:0.4608277358988649
test AP:0.1721753221434153
