Training fold 1
In epoch:000|batch:0000, train_loss:0.775956, train_ap:0.0896, train_acc:0.4219, train_auc:0.5021
In epoch:000|batch:0010, train_loss:0.392640, train_ap:0.8621, train_acc:0.9609, train_auc:0.9372
In epoch:000|batch:0020, train_loss:0.264683, train_ap:0.9283, train_acc:0.9844, train_auc:0.9681
In epoch:000|batch:0030, train_loss:0.226795, train_ap:0.8084, train_acc:0.9766, train_auc:0.8829
In epoch:000|batch:0000, val_loss:0.000820, val_ap:0.8234, val_acc:0.9766, val_auc:0.9195
In epoch:001|batch:0000, train_loss:0.085078, train_ap:0.8985, train_acc:0.9766, train_auc:0.9559
In epoch:001|batch:0010, train_loss:0.149050, train_ap:0.7568, train_acc:0.9531, train_auc:0.8131
In epoch:001|batch:0020, train_loss:0.170118, train_ap:0.7093, train_acc:0.9609, train_auc:0.9385
In epoch:001|batch:0030, train_loss:0.165289, train_ap:0.8302, train_acc:0.9375, train_auc:0.8797
In epoch:001|batch:0000, val_loss:0.001967, val_ap:0.7128, val_acc:0.9531, val_auc:0.8153
In epoch:002|batch:0000, train_loss:0.157841, train_ap:0.7765, train_acc:0.9609, train_auc:0.8968
In epoch:002|batch:0010, train_loss:0.181059, train_ap:0.4087, train_acc:0.9453, train_auc:0.6863
In epoch:002|batch:0020, train_loss:0.189600, train_ap:0.5697, train_acc:0.9219, train_auc:0.7414
In epoch:002|batch:0030, train_loss:0.190036, train_ap:0.6357, train_acc:0.9688, train_auc:0.8674
In epoch:002|batch:0000, val_loss:0.002030, val_ap:0.7145, val_acc:0.9297, val_auc:0.8116
In epoch:003|batch:0000, train_loss:0.183068, train_ap:0.5145, train_acc:0.9453, train_auc:0.8797
In epoch:003|batch:0010, train_loss:0.187511, train_ap:0.7625, train_acc:0.9531, train_auc:0.8972
In epoch:003|batch:0020, train_loss:0.189928, train_ap:0.7251, train_acc:0.9219, train_auc:0.8259
In epoch:003|batch:0030, train_loss:0.187317, train_ap:0.7238, train_acc:0.9141, train_auc:0.8551
In epoch:003|batch:0000, val_loss:0.001392, val_ap:0.5660, val_acc:0.9453, val_auc:0.8737
In epoch:004|batch:0000, train_loss:0.163623, train_ap:0.7387, train_acc:0.9531, train_auc:0.8901
In epoch:004|batch:0010, train_loss:0.175144, train_ap:0.7866, train_acc:0.9766, train_auc:0.8319
In epoch:004|batch:0020, train_loss:0.181524, train_ap:0.8470, train_acc:0.9531, train_auc:0.9455
In epoch:004|batch:0030, train_loss:0.180234, train_ap:0.8252, train_acc:0.9453, train_auc:0.9169
In epoch:004|batch:0000, val_loss:0.001035, val_ap:0.8999, val_acc:0.9688, val_auc:0.9247
In epoch:005|batch:0000, train_loss:0.255606, train_ap:0.5426, train_acc:0.9297, train_auc:0.8095
In epoch:005|batch:0010, train_loss:0.167641, train_ap:0.8243, train_acc:0.9531, train_auc:0.8861
In epoch:005|batch:0020, train_loss:0.175729, train_ap:0.8139, train_acc:0.9609, train_auc:0.9518
In epoch:005|batch:0030, train_loss:0.181726, train_ap:0.7532, train_acc:0.9609, train_auc:0.8408
In epoch:005|batch:0000, val_loss:0.002183, val_ap:0.6595, val_acc:0.9062, val_auc:0.8817
In epoch:006|batch:0000, train_loss:0.147610, train_ap:0.9070, train_acc:0.9375, train_auc:0.9401
In epoch:006|batch:0010, train_loss:0.160240, train_ap:0.7351, train_acc:0.9375, train_auc:0.8916
In epoch:006|batch:0020, train_loss:0.144993, train_ap:0.7625, train_acc:0.9766, train_auc:0.9219
In epoch:006|batch:0030, train_loss:0.142438, train_ap:0.7978, train_acc:0.9766, train_auc:0.9229
In epoch:006|batch:0000, val_loss:0.001322, val_ap:0.8289, val_acc:0.9609, val_auc:0.9425
In epoch:007|batch:0000, train_loss:0.083701, train_ap:0.9232, train_acc:0.9766, train_auc:0.9856
In epoch:007|batch:0010, train_loss:0.121423, train_ap:0.7730, train_acc:0.9766, train_auc:0.8786
In epoch:007|batch:0020, train_loss:0.117973, train_ap:0.8788, train_acc:0.9609, train_auc:0.9523
In epoch:007|batch:0030, train_loss:0.126729, train_ap:0.8269, train_acc:0.9531, train_auc:0.9449
In epoch:007|batch:0000, val_loss:0.000499, val_ap:0.9430, val_acc:0.9922, val_auc:0.9813
In epoch:008|batch:0000, train_loss:0.136883, train_ap:0.7909, train_acc:0.9688, train_auc:0.9325
In epoch:008|batch:0010, train_loss:0.122611, train_ap:0.9838, train_acc:0.9844, train_auc:0.9980
In epoch:008|batch:0020, train_loss:0.136854, train_ap:0.8373, train_acc:0.9531, train_auc:0.8816
In epoch:008|batch:0030, train_loss:0.133354, train_ap:0.7769, train_acc:0.9453, train_auc:0.9025
In epoch:008|batch:0000, val_loss:0.001019, val_ap:0.8446, val_acc:0.9688, val_auc:0.9156
In epoch:009|batch:0000, train_loss:0.175683, train_ap:0.8002, train_acc:0.9453, train_auc:0.9066
In epoch:009|batch:0010, train_loss:0.121850, train_ap:0.7413, train_acc:0.9609, train_auc:0.8515
In epoch:009|batch:0020, train_loss:0.128007, train_ap:0.9153, train_acc:0.9766, train_auc:0.9542
In epoch:009|batch:0030, train_loss:0.122718, train_ap:0.7936, train_acc:0.9219, train_auc:0.9375
In epoch:009|batch:0000, val_loss:0.001208, val_ap:0.8224, val_acc:0.9688, val_auc:0.9559
In epoch:010|batch:0000, train_loss:0.109805, train_ap:0.8721, train_acc:0.9688, train_auc:0.9896
In epoch:010|batch:0010, train_loss:0.119612, train_ap:0.8753, train_acc:0.9766, train_auc:0.9917
In epoch:010|batch:0020, train_loss:0.126735, train_ap:0.8682, train_acc:0.9688, train_auc:0.9697
In epoch:010|batch:0030, train_loss:0.124231, train_ap:0.8168, train_acc:0.9531, train_auc:0.8761
In epoch:010|batch:0000, val_loss:0.001044, val_ap:0.8460, val_acc:0.9609, val_auc:0.9392
In epoch:011|batch:0000, train_loss:0.119008, train_ap:0.8328, train_acc:0.9766, train_auc:0.8847
In epoch:011|batch:0010, train_loss:0.139596, train_ap:0.8151, train_acc:0.9531, train_auc:0.9135
In epoch:011|batch:0020, train_loss:0.140579, train_ap:0.8815, train_acc:0.9766, train_auc:0.9630
In epoch:011|batch:0030, train_loss:0.136770, train_ap:0.8677, train_acc:0.9844, train_auc:0.9619
In epoch:011|batch:0000, val_loss:0.000956, val_ap:0.8950, val_acc:0.9609, val_auc:0.9576
In epoch:012|batch:0000, train_loss:0.161714, train_ap:0.8354, train_acc:0.9688, train_auc:0.9015
In epoch:012|batch:0010, train_loss:0.135831, train_ap:0.8223, train_acc:0.9688, train_auc:0.9301
In epoch:012|batch:0020, train_loss:0.126140, train_ap:0.7980, train_acc:0.9609, train_auc:0.8737
In epoch:012|batch:0030, train_loss:0.132556, train_ap:0.7463, train_acc:0.9453, train_auc:0.8508
In epoch:012|batch:0000, val_loss:0.001142, val_ap:0.7798, val_acc:0.9688, val_auc:0.8998
In epoch:013|batch:0000, train_loss:0.161950, train_ap:0.8828, train_acc:0.9453, train_auc:0.9518
In epoch:013|batch:0010, train_loss:0.120117, train_ap:0.8231, train_acc:0.9766, train_auc:0.8916
In epoch:013|batch:0020, train_loss:0.122506, train_ap:0.9053, train_acc:0.9688, train_auc:0.9505
In epoch:013|batch:0030, train_loss:0.125889, train_ap:0.9643, train_acc:0.9844, train_auc:0.9935
In epoch:013|batch:0000, val_loss:0.000740, val_ap:0.8324, val_acc:0.9844, val_auc:0.9136
In epoch:014|batch:0000, train_loss:0.083922, train_ap:0.8856, train_acc:0.9766, train_auc:0.9841
In epoch:014|batch:0010, train_loss:0.124747, train_ap:0.8347, train_acc:0.9844, train_auc:0.8361
In epoch:014|batch:0020, train_loss:0.131473, train_ap:0.8796, train_acc:0.9688, train_auc:0.9711
In epoch:014|batch:0030, train_loss:0.125510, train_ap:0.8423, train_acc:0.9609, train_auc:0.8835
In epoch:014|batch:0000, val_loss:0.001423, val_ap:0.7815, val_acc:0.9609, val_auc:0.9425
Best val_loss is: 0.0010486
In test batch:0000
In test batch:0010
In test batch:0020
Training fold 2
In epoch:000|batch:0000, train_loss:0.731167, train_ap:0.0733, train_acc:0.5312, train_auc:0.2080
In epoch:000|batch:0010, train_loss:0.460760, train_ap:0.1528, train_acc:0.9297, train_auc:0.7804
In epoch:000|batch:0020, train_loss:0.379419, train_ap:0.3946, train_acc:0.8516, train_auc:0.7287
In epoch:000|batch:0030, train_loss:0.345809, train_ap:0.0367, train_acc:0.9688, train_auc:0.6944
In epoch:000|batch:0000, val_loss:0.001742, val_ap:0.3466, val_acc:0.9375, val_auc:0.7386
In epoch:001|batch:0000, train_loss:0.428868, train_ap:0.4907, train_acc:0.8516, train_auc:0.7677
In epoch:001|batch:0010, train_loss:0.265513, train_ap:0.3070, train_acc:0.9219, train_auc:0.7576
In epoch:001|batch:0020, train_loss:0.255272, train_ap:0.2616, train_acc:0.8750, train_auc:0.7243
In epoch:001|batch:0030, train_loss:0.271391, train_ap:0.2472, train_acc:0.8984, train_auc:0.6883
In epoch:001|batch:0000, val_loss:0.002046, val_ap:0.2132, val_acc:0.9297, val_auc:0.7021
In epoch:002|batch:0000, train_loss:0.404365, train_ap:0.3095, train_acc:0.8516, train_auc:0.6859
In epoch:002|batch:0010, train_loss:0.285509, train_ap:0.1176, train_acc:0.9062, train_auc:0.5805
In epoch:002|batch:0020, train_loss:0.292304, train_ap:0.5288, train_acc:0.8984, train_auc:0.7963
In epoch:002|batch:0030, train_loss:0.284345, train_ap:0.2360, train_acc:0.9141, train_auc:0.7102
In epoch:002|batch:0000, val_loss:0.002525, val_ap:0.3152, val_acc:0.8906, val_auc:0.8158
In epoch:003|batch:0000, train_loss:0.328790, train_ap:0.2500, train_acc:0.8750, train_auc:0.7699
In epoch:003|batch:0010, train_loss:0.284735, train_ap:0.4581, train_acc:0.8984, train_auc:0.8328
In epoch:003|batch:0020, train_loss:0.270007, train_ap:0.3878, train_acc:0.9219, train_auc:0.8583
In epoch:003|batch:0030, train_loss:0.264471, train_ap:0.3906, train_acc:0.8828, train_auc:0.7563
In epoch:003|batch:0000, val_loss:0.001777, val_ap:0.3713, val_acc:0.9219, val_auc:0.7466
In epoch:004|batch:0000, train_loss:0.223077, train_ap:0.5049, train_acc:0.9141, train_auc:0.8391
In epoch:004|batch:0010, train_loss:0.238405, train_ap:0.3758, train_acc:0.8906, train_auc:0.7199
In epoch:004|batch:0020, train_loss:0.247061, train_ap:0.5165, train_acc:0.8828, train_auc:0.7740
In epoch:004|batch:0030, train_loss:0.241845, train_ap:0.1528, train_acc:0.9297, train_auc:0.8019
In epoch:004|batch:0000, val_loss:0.002275, val_ap:0.5641, val_acc:0.9062, val_auc:0.8047
In epoch:005|batch:0000, train_loss:0.256328, train_ap:0.5784, train_acc:0.8984, train_auc:0.8366
In epoch:005|batch:0010, train_loss:0.181892, train_ap:0.7857, train_acc:0.9453, train_auc:0.8783
In epoch:005|batch:0020, train_loss:0.177283, train_ap:0.7197, train_acc:0.9766, train_auc:0.9180
In epoch:005|batch:0030, train_loss:0.170226, train_ap:0.8376, train_acc:0.9531, train_auc:0.9131
In epoch:005|batch:0000, val_loss:0.001021, val_ap:0.7819, val_acc:0.9688, val_auc:0.9093
In epoch:006|batch:0000, train_loss:0.085245, train_ap:0.9086, train_acc:0.9766, train_auc:0.9869
In epoch:006|batch:0010, train_loss:0.150828, train_ap:0.6718, train_acc:0.9453, train_auc:0.7632
In epoch:006|batch:0020, train_loss:0.136764, train_ap:0.8202, train_acc:0.9688, train_auc:0.8720
In epoch:006|batch:0030, train_loss:0.129454, train_ap:0.9866, train_acc:0.9922, train_auc:0.9974
In epoch:006|batch:0000, val_loss:0.000720, val_ap:0.9185, val_acc:0.9766, val_auc:0.9864
In epoch:007|batch:0000, train_loss:0.216277, train_ap:0.6213, train_acc:0.9453, train_auc:0.8288
In epoch:007|batch:0010, train_loss:0.116779, train_ap:0.8822, train_acc:0.9766, train_auc:0.9639
In epoch:007|batch:0020, train_loss:0.099252, train_ap:0.8973, train_acc:0.9766, train_auc:0.9828
In epoch:007|batch:0030, train_loss:0.114342, train_ap:1.0000, train_acc:1.0000, train_auc:1.0000
In epoch:007|batch:0000, val_loss:0.001513, val_ap:0.7572, val_acc:0.9453, val_auc:0.9091
In epoch:008|batch:0000, train_loss:0.215760, train_ap:0.7141, train_acc:0.9531, train_auc:0.8330
In epoch:008|batch:0010, train_loss:0.131382, train_ap:0.8503, train_acc:0.9766, train_auc:0.9596
In epoch:008|batch:0020, train_loss:0.112617, train_ap:0.7676, train_acc:0.9688, train_auc:0.8671
In epoch:008|batch:0030, train_loss:0.108512, train_ap:0.8976, train_acc:0.9922, train_auc:0.9010
In epoch:008|batch:0000, val_loss:0.000932, val_ap:0.8416, val_acc:0.9688, val_auc:0.9726
In epoch:009|batch:0000, train_loss:0.166246, train_ap:0.9150, train_acc:0.9609, train_auc:0.9430
In epoch:009|batch:0010, train_loss:0.115481, train_ap:1.0000, train_acc:0.9922, train_auc:1.0000
In epoch:009|batch:0020, train_loss:0.114009, train_ap:0.8827, train_acc:0.9844, train_auc:0.9599
In epoch:009|batch:0030, train_loss:0.116521, train_ap:0.8529, train_acc:0.9844, train_auc:0.9223
In epoch:009|batch:0000, val_loss:0.001451, val_ap:0.6527, val_acc:0.9609, val_auc:0.7907
In epoch:010|batch:0000, train_loss:0.102841, train_ap:0.9517, train_acc:0.9766, train_auc:0.9875
In epoch:010|batch:0010, train_loss:0.105612, train_ap:0.8509, train_acc:0.9766, train_auc:0.9432
In epoch:010|batch:0020, train_loss:0.097423, train_ap:1.0000, train_acc:1.0000, train_auc:1.0000
In epoch:010|batch:0030, train_loss:0.108758, train_ap:0.6664, train_acc:0.9453, train_auc:0.8702
In epoch:010|batch:0000, val_loss:0.001853, val_ap:0.5400, val_acc:0.9297, val_auc:0.8733
In epoch:011|batch:0000, train_loss:0.151165, train_ap:0.8896, train_acc:0.9688, train_auc:0.9090
In epoch:011|batch:0010, train_loss:0.112815, train_ap:0.9190, train_acc:0.9688, train_auc:0.9878
In epoch:011|batch:0020, train_loss:0.105560, train_ap:0.9138, train_acc:0.9844, train_auc:0.9599
In epoch:011|batch:0030, train_loss:0.112713, train_ap:0.9387, train_acc:0.9766, train_auc:0.9656
In epoch:011|batch:0000, val_loss:0.001141, val_ap:0.7215, val_acc:0.9609, val_auc:0.9589
In epoch:012|batch:0000, train_loss:0.122158, train_ap:0.8596, train_acc:0.9609, train_auc:0.9404
In epoch:012|batch:0010, train_loss:0.123588, train_ap:0.9924, train_acc:0.9844, train_auc:0.9992
In epoch:012|batch:0020, train_loss:0.115881, train_ap:0.8439, train_acc:0.9688, train_auc:0.9184
In epoch:012|batch:0030, train_loss:0.111496, train_ap:0.7130, train_acc:0.9688, train_auc:0.8722
In epoch:012|batch:0000, val_loss:0.000641, val_ap:0.8897, val_acc:0.9844, val_auc:0.9622
In epoch:013|batch:0000, train_loss:0.142097, train_ap:0.8625, train_acc:0.9688, train_auc:0.9327
In epoch:013|batch:0010, train_loss:0.107974, train_ap:0.8249, train_acc:0.9688, train_auc:0.9179
In epoch:013|batch:0020, train_loss:0.105356, train_ap:0.8156, train_acc:0.9531, train_auc:0.9018
In epoch:013|batch:0030, train_loss:0.107004, train_ap:0.7150, train_acc:0.9531, train_auc:0.8288
In epoch:013|batch:0000, val_loss:0.001238, val_ap:0.8684, val_acc:0.9453, val_auc:0.9740
In epoch:014|batch:0000, train_loss:0.054461, train_ap:0.9809, train_acc:0.9766, train_auc:0.9983
In epoch:014|batch:0010, train_loss:0.111664, train_ap:0.7212, train_acc:0.9453, train_auc:0.9504
In epoch:014|batch:0020, train_loss:0.119413, train_ap:0.9030, train_acc:0.9844, train_auc:0.9814
In epoch:014|batch:0030, train_loss:0.111662, train_ap:1.0000, train_acc:1.0000, train_auc:1.0000
In epoch:014|batch:0000, val_loss:0.000933, val_ap:0.8650, val_acc:0.9688, val_auc:0.9645
Best val_loss is: 0.0010302
In test batch:0000
In test batch:0010
In test batch:0020
Training fold 3
In epoch:000|batch:0000, train_loss:0.823565, train_ap:0.1864, train_acc:0.3281, train_auc:0.6214
In epoch:000|batch:0010, train_loss:0.443186, train_ap:0.7699, train_acc:0.9531, train_auc:0.8499
In epoch:000|batch:0020, train_loss:0.303130, train_ap:0.9485, train_acc:0.9766, train_auc:0.9714
In epoch:000|batch:0030, train_loss:0.246263, train_ap:0.8489, train_acc:0.9766, train_auc:0.9347
In epoch:000|batch:0000, val_loss:0.001431, val_ap:0.7846, val_acc:0.9531, val_auc:0.9204
In epoch:001|batch:0000, train_loss:0.103272, train_ap:0.8572, train_acc:0.9766, train_auc:0.9588
In epoch:001|batch:0010, train_loss:0.110220, train_ap:0.8687, train_acc:0.9844, train_auc:0.9669
In epoch:001|batch:0020, train_loss:0.105767, train_ap:0.7838, train_acc:0.9688, train_auc:0.9037
In epoch:001|batch:0030, train_loss:0.108123, train_ap:0.8158, train_acc:0.9688, train_auc:0.9398
In epoch:001|batch:0000, val_loss:0.001318, val_ap:0.7042, val_acc:0.9531, val_auc:0.8693
In epoch:002|batch:0000, train_loss:0.108611, train_ap:0.8547, train_acc:0.9766, train_auc:0.9411
In epoch:002|batch:0010, train_loss:0.097151, train_ap:0.5382, train_acc:0.9219, train_auc:0.8465
In epoch:002|batch:0020, train_loss:0.100396, train_ap:0.7546, train_acc:0.9766, train_auc:0.9917
In epoch:002|batch:0030, train_loss:0.108567, train_ap:0.9254, train_acc:0.9688, train_auc:0.9711
In epoch:002|batch:0000, val_loss:0.000740, val_ap:0.9047, val_acc:0.9766, val_auc:0.9436
In epoch:003|batch:0000, train_loss:0.090158, train_ap:0.9604, train_acc:0.9766, train_auc:0.9889
In epoch:003|batch:0010, train_loss:0.101235, train_ap:0.7523, train_acc:0.9609, train_auc:0.8873
In epoch:003|batch:0020, train_loss:0.109336, train_ap:0.8368, train_acc:0.9609, train_auc:0.9281
In epoch:003|batch:0030, train_loss:0.111385, train_ap:0.8899, train_acc:0.9844, train_auc:0.9430
In epoch:003|batch:0000, val_loss:0.000907, val_ap:0.8588, val_acc:0.9766, val_auc:0.9353
In epoch:004|batch:0000, train_loss:0.131221, train_ap:0.7018, train_acc:0.9688, train_auc:0.8500
In epoch:004|batch:0010, train_loss:0.106471, train_ap:0.9260, train_acc:0.9766, train_auc:0.9627
In epoch:004|batch:0020, train_loss:0.104510, train_ap:0.8578, train_acc:0.9609, train_auc:0.9635
In epoch:004|batch:0030, train_loss:0.101736, train_ap:0.9909, train_acc:0.9922, train_auc:0.9992
In epoch:004|batch:0000, val_loss:0.001037, val_ap:0.8267, val_acc:0.9609, val_auc:0.9534
In epoch:005|batch:0000, train_loss:0.152345, train_ap:0.7118, train_acc:0.9688, train_auc:0.8385
In epoch:005|batch:0010, train_loss:0.117024, train_ap:0.9318, train_acc:0.9922, train_auc:0.9612
In epoch:005|batch:0020, train_loss:0.107842, train_ap:0.7963, train_acc:0.9688, train_auc:0.9008
In epoch:005|batch:0030, train_loss:0.106435, train_ap:0.8304, train_acc:0.9688, train_auc:0.9661
In epoch:005|batch:0000, val_loss:0.001015, val_ap:0.8228, val_acc:0.9766, val_auc:0.8548
In epoch:006|batch:0000, train_loss:0.082198, train_ap:0.8035, train_acc:0.9844, train_auc:0.9427
In epoch:006|batch:0010, train_loss:0.087185, train_ap:0.9315, train_acc:0.9844, train_auc:0.9864
In epoch:006|batch:0020, train_loss:0.100897, train_ap:0.7855, train_acc:0.9453, train_auc:0.9248
In epoch:006|batch:0030, train_loss:0.092323, train_ap:0.9331, train_acc:0.9766, train_auc:0.9932
In epoch:006|batch:0000, val_loss:0.000814, val_ap:0.8893, val_acc:0.9766, val_auc:0.9518
In epoch:007|batch:0000, train_loss:0.146110, train_ap:0.8410, train_acc:0.9531, train_auc:0.9342
In epoch:007|batch:0010, train_loss:0.104990, train_ap:1.0000, train_acc:0.9922, train_auc:1.0000
In epoch:007|batch:0020, train_loss:0.102563, train_ap:0.9076, train_acc:0.9766, train_auc:0.9777
In epoch:007|batch:0030, train_loss:0.098710, train_ap:0.8551, train_acc:0.9766, train_auc:0.9454
In epoch:007|batch:0000, val_loss:0.000475, val_ap:0.9603, val_acc:0.9844, val_auc:0.9940
In epoch:008|batch:0000, train_loss:0.057069, train_ap:0.9685, train_acc:0.9766, train_auc:0.9957
In epoch:008|batch:0010, train_loss:0.100282, train_ap:0.8805, train_acc:0.9688, train_auc:0.9456
In epoch:008|batch:0020, train_loss:0.094641, train_ap:0.7626, train_acc:0.9688, train_auc:0.9085
In epoch:008|batch:0030, train_loss:0.097997, train_ap:0.8515, train_acc:0.9922, train_auc:0.9331
In epoch:008|batch:0000, val_loss:0.000863, val_ap:0.9279, val_acc:0.9688, val_auc:0.9621
In epoch:009|batch:0000, train_loss:0.127727, train_ap:0.8746, train_acc:0.9688, train_auc:0.9280
In epoch:009|batch:0010, train_loss:0.103627, train_ap:0.9911, train_acc:0.9844, train_auc:0.9987
In epoch:009|batch:0020, train_loss:0.092573, train_ap:0.9682, train_acc:0.9844, train_auc:0.9894
In epoch:009|batch:0030, train_loss:0.088808, train_ap:0.8794, train_acc:0.9844, train_auc:0.9407
In epoch:009|batch:0000, val_loss:0.000272, val_ap:1.0000, val_acc:0.9922, val_auc:1.0000
In epoch:010|batch:0000, train_loss:0.074914, train_ap:0.9525, train_acc:0.9766, train_auc:0.9860
In epoch:010|batch:0010, train_loss:0.093153, train_ap:0.9361, train_acc:0.9844, train_auc:0.9572
In epoch:010|batch:0020, train_loss:0.094197, train_ap:0.9571, train_acc:0.9766, train_auc:0.9868
In epoch:010|batch:0030, train_loss:0.090373, train_ap:1.0000, train_acc:0.9922, train_auc:1.0000
In epoch:010|batch:0000, val_loss:0.000847, val_ap:0.9256, val_acc:0.9766, val_auc:0.9282
In epoch:011|batch:0000, train_loss:0.082540, train_ap:0.8912, train_acc:0.9766, train_auc:0.9899
In epoch:011|batch:0010, train_loss:0.122947, train_ap:0.7876, train_acc:0.9766, train_auc:0.9850
In epoch:011|batch:0020, train_loss:0.091905, train_ap:0.9552, train_acc:0.9766, train_auc:0.9912
In epoch:011|batch:0030, train_loss:0.099780, train_ap:0.8515, train_acc:0.9531, train_auc:0.9720
In epoch:011|batch:0000, val_loss:0.000984, val_ap:0.9326, val_acc:0.9766, val_auc:0.9492
In epoch:012|batch:0000, train_loss:0.087664, train_ap:0.9390, train_acc:0.9688, train_auc:0.9881
In epoch:012|batch:0010, train_loss:0.100514, train_ap:0.8020, train_acc:0.9766, train_auc:0.9093
In epoch:012|batch:0020, train_loss:0.094165, train_ap:0.8651, train_acc:0.9688, train_auc:0.9814
In epoch:012|batch:0030, train_loss:0.090869, train_ap:0.9397, train_acc:0.9766, train_auc:0.9899
In epoch:012|batch:0000, val_loss:0.000246, val_ap:0.9909, val_acc:0.9922, val_auc:0.9992
In epoch:013|batch:0000, train_loss:0.108951, train_ap:0.8652, train_acc:0.9688, train_auc:0.9605
In epoch:013|batch:0010, train_loss:0.110520, train_ap:0.9228, train_acc:0.9766, train_auc:0.9839
In epoch:013|batch:0020, train_loss:0.097659, train_ap:0.9085, train_acc:0.9688, train_auc:0.9821
In epoch:013|batch:0030, train_loss:0.094157, train_ap:0.9777, train_acc:0.9844, train_auc:0.9977
In epoch:013|batch:0000, val_loss:0.000896, val_ap:0.9223, val_acc:0.9688, val_auc:0.9772
In epoch:014|batch:0000, train_loss:0.060785, train_ap:0.9678, train_acc:0.9844, train_auc:0.9917
In epoch:014|batch:0010, train_loss:0.096138, train_ap:0.9373, train_acc:0.9766, train_auc:0.9899
In epoch:014|batch:0020, train_loss:0.095976, train_ap:1.0000, train_acc:0.9922, train_auc:1.0000
In epoch:014|batch:0030, train_loss:0.089271, train_ap:0.9532, train_acc:0.9844, train_auc:0.9949
In epoch:014|batch:0000, val_loss:0.000413, val_ap:0.9020, val_acc:0.9922, val_auc:0.9698
Best val_loss is: 0.0007243
In test batch:0000
In test batch:0010
In test batch:0020
Training fold 4
In epoch:000|batch:0000, train_loss:0.784140, train_ap:0.1541, train_acc:0.3906, train_auc:0.5431
In epoch:000|batch:0010, train_loss:0.414012, train_ap:0.7715, train_acc:0.9609, train_auc:0.8741
In epoch:000|batch:0020, train_loss:0.282181, train_ap:0.9861, train_acc:0.9844, train_auc:0.9990
In epoch:000|batch:0030, train_loss:0.228267, train_ap:1.0000, train_acc:1.0000, train_auc:1.0000
In epoch:000|batch:0000, val_loss:0.000969, val_ap:0.8161, val_acc:0.9844, val_auc:0.8161
In epoch:001|batch:0000, train_loss:0.059310, train_ap:0.9071, train_acc:0.9922, train_auc:0.9570
In epoch:001|batch:0010, train_loss:0.115205, train_ap:0.5265, train_acc:0.9297, train_auc:0.8365
In epoch:001|batch:0020, train_loss:0.117143, train_ap:1.0000, train_acc:1.0000, train_auc:1.0000
In epoch:001|batch:0030, train_loss:0.110332, train_ap:0.8661, train_acc:0.9766, train_auc:0.9669
In epoch:001|batch:0000, val_loss:0.000198, val_ap:1.0000, val_acc:1.0000, val_auc:1.0000
In epoch:002|batch:0000, train_loss:0.188392, train_ap:0.7639, train_acc:0.9531, train_auc:0.8177
In epoch:002|batch:0010, train_loss:0.133228, train_ap:0.9040, train_acc:0.9766, train_auc:0.9468
In epoch:002|batch:0020, train_loss:0.119946, train_ap:0.9372, train_acc:0.9688, train_auc:0.9776
In epoch:002|batch:0030, train_loss:0.114212, train_ap:0.9167, train_acc:0.9844, train_auc:0.9835
In epoch:002|batch:0000, val_loss:0.000354, val_ap:0.9667, val_acc:0.9922, val_auc:0.9943
In epoch:003|batch:0000, train_loss:0.071288, train_ap:0.9613, train_acc:0.9844, train_auc:0.9950
In epoch:003|batch:0010, train_loss:0.113316, train_ap:0.8312, train_acc:0.9766, train_auc:0.9365
In epoch:003|batch:0020, train_loss:0.115383, train_ap:0.8994, train_acc:0.9609, train_auc:0.9609
In epoch:003|batch:0030, train_loss:0.113318, train_ap:0.7653, train_acc:0.9688, train_auc:0.8337
In epoch:003|batch:0000, val_loss:0.000611, val_ap:0.8239, val_acc:0.9844, val_auc:0.9448
In epoch:004|batch:0000, train_loss:0.097954, train_ap:0.8774, train_acc:0.9766, train_auc:0.9382
In epoch:004|batch:0010, train_loss:0.103639, train_ap:0.9164, train_acc:0.9766, train_auc:0.9487
In epoch:004|batch:0020, train_loss:0.115057, train_ap:0.8270, train_acc:0.9609, train_auc:0.9565
In epoch:004|batch:0030, train_loss:0.115367, train_ap:0.6709, train_acc:0.9844, train_auc:0.9031
In epoch:004|batch:0000, val_loss:0.000351, val_ap:1.0000, val_acc:0.9922, val_auc:1.0000
In epoch:005|batch:0000, train_loss:0.067864, train_ap:0.9183, train_acc:0.9844, train_auc:0.9751
In epoch:005|batch:0010, train_loss:0.085370, train_ap:0.8229, train_acc:0.9766, train_auc:0.9394
In epoch:005|batch:0020, train_loss:0.094873, train_ap:0.8526, train_acc:0.9609, train_auc:0.9569
In epoch:005|batch:0030, train_loss:0.108594, train_ap:0.7581, train_acc:0.9688, train_auc:0.9231
In epoch:005|batch:0000, val_loss:0.000613, val_ap:0.8334, val_acc:0.9844, val_auc:0.9891
In epoch:006|batch:0000, train_loss:0.239028, train_ap:0.6658, train_acc:0.9375, train_auc:0.8153
In epoch:006|batch:0010, train_loss:0.105594, train_ap:1.0000, train_acc:1.0000, train_auc:1.0000
In epoch:006|batch:0020, train_loss:0.104659, train_ap:0.7435, train_acc:0.9688, train_auc:0.9021
In epoch:006|batch:0030, train_loss:0.105490, train_ap:0.8631, train_acc:0.9609, train_auc:0.9359
In epoch:006|batch:0000, val_loss:0.000927, val_ap:0.8755, val_acc:0.9688, val_auc:0.9380
In epoch:007|batch:0000, train_loss:0.066494, train_ap:0.9389, train_acc:0.9766, train_auc:0.9763
In epoch:007|batch:0010, train_loss:0.113090, train_ap:0.8685, train_acc:0.9766, train_auc:0.9592
In epoch:007|batch:0020, train_loss:0.109354, train_ap:0.8989, train_acc:0.9766, train_auc:0.9644
In epoch:007|batch:0030, train_loss:0.105320, train_ap:0.9076, train_acc:0.9766, train_auc:0.9605
In epoch:007|batch:0000, val_loss:0.001103, val_ap:0.8787, val_acc:0.9531, val_auc:0.9806
In epoch:008|batch:0000, train_loss:0.022671, train_ap:1.0000, train_acc:1.0000, train_auc:1.0000
In epoch:008|batch:0010, train_loss:0.104676, train_ap:0.9327, train_acc:0.9688, train_auc:0.9758
In epoch:008|batch:0020, train_loss:0.105991, train_ap:0.9233, train_acc:0.9688, train_auc:0.9822
In epoch:008|batch:0030, train_loss:0.103127, train_ap:0.7767, train_acc:0.9844, train_auc:0.9585
In epoch:008|batch:0000, val_loss:0.001578, val_ap:0.7603, val_acc:0.9531, val_auc:0.8996
In epoch:009|batch:0000, train_loss:0.058616, train_ap:0.9431, train_acc:0.9844, train_auc:0.9753
In epoch:009|batch:0010, train_loss:0.102514, train_ap:0.7533, train_acc:0.9609, train_auc:0.9050
In epoch:009|batch:0020, train_loss:0.096226, train_ap:0.9204, train_acc:0.9922, train_auc:0.9669
In epoch:009|batch:0030, train_loss:0.094549, train_ap:0.9765, train_acc:0.9844, train_auc:0.9981
In epoch:009|batch:0000, val_loss:0.000656, val_ap:0.9026, val_acc:0.9766, val_auc:0.9775
In epoch:010|batch:0000, train_loss:0.032444, train_ap:1.0000, train_acc:0.9844, train_auc:1.0000
In epoch:010|batch:0010, train_loss:0.094812, train_ap:0.8233, train_acc:0.9688, train_auc:0.9286
In epoch:010|batch:0020, train_loss:0.105776, train_ap:0.8518, train_acc:0.9453, train_auc:0.9585
In epoch:010|batch:0030, train_loss:0.103308, train_ap:0.8584, train_acc:0.9688, train_auc:0.9612
In epoch:010|batch:0000, val_loss:0.000352, val_ap:1.0000, val_acc:0.9922, val_auc:1.0000
In epoch:011|batch:0000, train_loss:0.104001, train_ap:0.8571, train_acc:0.9609, train_auc:0.9655
In epoch:011|batch:0010, train_loss:0.122090, train_ap:0.9306, train_acc:0.9531, train_auc:0.9888
In epoch:011|batch:0020, train_loss:0.105264, train_ap:0.8741, train_acc:0.9766, train_auc:0.9476
In epoch:011|batch:0030, train_loss:0.102707, train_ap:0.9333, train_acc:0.9922, train_auc:0.9945
In epoch:011|batch:0000, val_loss:0.000075, val_ap:1.0000, val_acc:1.0000, val_auc:1.0000
In epoch:012|batch:0000, train_loss:0.103056, train_ap:0.9207, train_acc:0.9688, train_auc:0.9782
In epoch:012|batch:0010, train_loss:0.086711, train_ap:0.9377, train_acc:0.9922, train_auc:0.9814
In epoch:012|batch:0020, train_loss:0.088668, train_ap:0.9881, train_acc:0.9844, train_auc:0.9986
In epoch:012|batch:0030, train_loss:0.092851, train_ap:0.8515, train_acc:0.9531, train_auc:0.9741
In epoch:012|batch:0000, val_loss:0.000736, val_ap:0.9122, val_acc:0.9766, val_auc:0.9883
In epoch:013|batch:0000, train_loss:0.076622, train_ap:0.9216, train_acc:0.9766, train_auc:0.9883
In epoch:013|batch:0010, train_loss:0.104044, train_ap:0.8936, train_acc:0.9844, train_auc:0.9625
In epoch:013|batch:0020, train_loss:0.094975, train_ap:0.9296, train_acc:0.9688, train_auc:0.9799
In epoch:013|batch:0030, train_loss:0.095313, train_ap:0.6987, train_acc:0.9297, train_auc:0.9302
In epoch:013|batch:0000, val_loss:0.000996, val_ap:0.8038, val_acc:0.9688, val_auc:0.8831
In epoch:014|batch:0000, train_loss:0.158177, train_ap:0.8560, train_acc:0.9609, train_auc:0.9330
In epoch:014|batch:0010, train_loss:0.095973, train_ap:1.0000, train_acc:0.9922, train_auc:1.0000
In epoch:014|batch:0020, train_loss:0.085925, train_ap:0.8864, train_acc:0.9688, train_auc:0.9648
In epoch:014|batch:0030, train_loss:0.087600, train_ap:0.8240, train_acc:0.9688, train_auc:0.9896
In epoch:014|batch:0000, val_loss:0.000747, val_ap:0.9726, val_acc:0.9766, val_auc:0.9937
Best val_loss is: 0.0006953
In test batch:0000
In test batch:0010
In test batch:0020
Training fold 5
In epoch:000|batch:0000, train_loss:0.718556, train_ap:0.2766, train_acc:0.5156, train_auc:0.6868
In epoch:000|batch:0010, train_loss:0.354106, train_ap:0.6593, train_acc:0.9688, train_auc:0.8339
In epoch:000|batch:0020, train_loss:0.283828, train_ap:0.6885, train_acc:0.9609, train_auc:0.7306
In epoch:000|batch:0030, train_loss:0.277772, train_ap:0.2018, train_acc:0.9531, train_auc:0.5691
In epoch:000|batch:0000, val_loss:0.004067, val_ap:0.2441, val_acc:0.8828, val_auc:0.7422
In epoch:001|batch:0000, train_loss:0.244368, train_ap:0.3108, train_acc:0.9141, train_auc:0.7051
In epoch:001|batch:0010, train_loss:0.266343, train_ap:0.4351, train_acc:0.9375, train_auc:0.7918
In epoch:001|batch:0020, train_loss:0.279761, train_ap:0.4618, train_acc:0.9375, train_auc:0.7824
In epoch:001|batch:0030, train_loss:0.261176, train_ap:0.1516, train_acc:0.9453, train_auc:0.7623
In epoch:001|batch:0000, val_loss:0.002405, val_ap:0.5041, val_acc:0.8672, val_auc:0.8060
In epoch:002|batch:0000, train_loss:0.224116, train_ap:0.4502, train_acc:0.9297, train_auc:0.7415
In epoch:002|batch:0010, train_loss:0.251543, train_ap:0.4055, train_acc:0.9062, train_auc:0.8341
In epoch:002|batch:0020, train_loss:0.233525, train_ap:0.5873, train_acc:0.9062, train_auc:0.7310
In epoch:002|batch:0030, train_loss:0.220755, train_ap:0.5660, train_acc:0.9609, train_auc:0.8996
In epoch:002|batch:0000, val_loss:0.003344, val_ap:0.7833, val_acc:0.7500, val_auc:0.9073
In epoch:003|batch:0000, train_loss:0.134530, train_ap:0.6625, train_acc:0.9453, train_auc:0.9583
In epoch:003|batch:0010, train_loss:0.175744, train_ap:0.7576, train_acc:0.9453, train_auc:0.8432
In epoch:003|batch:0020, train_loss:0.165212, train_ap:0.7155, train_acc:0.9531, train_auc:0.8492
In epoch:003|batch:0030, train_loss:0.155822, train_ap:0.9958, train_acc:0.9922, train_auc:0.9994
In epoch:003|batch:0000, val_loss:0.000733, val_ap:0.8712, val_acc:0.9688, val_auc:0.9144
In epoch:004|batch:0000, train_loss:0.061393, train_ap:0.9379, train_acc:0.9844, train_auc:0.9868
In epoch:004|batch:0010, train_loss:0.107207, train_ap:0.8131, train_acc:0.9531, train_auc:0.8712
In epoch:004|batch:0020, train_loss:0.117341, train_ap:0.8814, train_acc:0.9453, train_auc:0.9481
In epoch:004|batch:0030, train_loss:0.126199, train_ap:0.6746, train_acc:0.9453, train_auc:0.8749
In epoch:004|batch:0000, val_loss:0.001140, val_ap:0.8886, val_acc:0.9688, val_auc:0.9541
In epoch:005|batch:0000, train_loss:0.221946, train_ap:0.6951, train_acc:0.9375, train_auc:0.8578
In epoch:005|batch:0010, train_loss:0.192845, train_ap:0.8605, train_acc:0.9844, train_auc:0.9402
In epoch:005|batch:0020, train_loss:0.170276, train_ap:0.8133, train_acc:0.9766, train_auc:0.8866
In epoch:005|batch:0030, train_loss:0.171941, train_ap:0.8585, train_acc:0.9766, train_auc:0.9871
In epoch:005|batch:0000, val_loss:0.001624, val_ap:0.8263, val_acc:0.9844, val_auc:0.9463
In epoch:006|batch:0000, train_loss:0.138943, train_ap:0.8168, train_acc:0.9766, train_auc:0.8229
In epoch:006|batch:0010, train_loss:0.170943, train_ap:0.8854, train_acc:0.9766, train_auc:0.9650
In epoch:006|batch:0020, train_loss:0.147304, train_ap:0.9838, train_acc:0.9844, train_auc:0.9980
In epoch:006|batch:0030, train_loss:0.140467, train_ap:0.6815, train_acc:0.9766, train_auc:0.7780
In epoch:006|batch:0000, val_loss:0.000632, val_ap:0.9081, val_acc:0.9844, val_auc:0.9596
In epoch:007|batch:0000, train_loss:0.125537, train_ap:0.9226, train_acc:0.9609, train_auc:0.9556
In epoch:007|batch:0010, train_loss:0.125440, train_ap:0.6868, train_acc:0.9609, train_auc:0.7839
In epoch:007|batch:0020, train_loss:0.116731, train_ap:0.8995, train_acc:0.9609, train_auc:0.9833
In epoch:007|batch:0030, train_loss:0.124391, train_ap:0.7985, train_acc:0.9609, train_auc:0.9123
In epoch:007|batch:0000, val_loss:0.001484, val_ap:0.7884, val_acc:0.9531, val_auc:0.8950
In epoch:008|batch:0000, train_loss:0.183819, train_ap:0.8280, train_acc:0.9453, train_auc:0.9208
In epoch:008|batch:0010, train_loss:0.164539, train_ap:0.9064, train_acc:0.9766, train_auc:0.9311
In epoch:008|batch:0020, train_loss:0.182868, train_ap:0.9144, train_acc:0.9531, train_auc:0.9897
In epoch:008|batch:0030, train_loss:0.165597, train_ap:0.7090, train_acc:0.9688, train_auc:0.8711
In epoch:008|batch:0000, val_loss:0.000787, val_ap:0.8998, val_acc:0.9688, val_auc:0.9212
In epoch:009|batch:0000, train_loss:0.127016, train_ap:0.8612, train_acc:0.9609, train_auc:0.8923
In epoch:009|batch:0010, train_loss:0.139992, train_ap:0.7971, train_acc:0.9688, train_auc:0.9619
In epoch:009|batch:0020, train_loss:0.129612, train_ap:0.8794, train_acc:0.9844, train_auc:0.9552
In epoch:009|batch:0030, train_loss:0.129895, train_ap:0.7893, train_acc:0.9766, train_auc:0.8664
In epoch:009|batch:0000, val_loss:0.001050, val_ap:0.8864, val_acc:0.9531, val_auc:0.9874
In epoch:010|batch:0000, train_loss:0.028238, train_ap:1.0000, train_acc:1.0000, train_auc:1.0000
In epoch:010|batch:0010, train_loss:0.111851, train_ap:0.8848, train_acc:0.9844, train_auc:0.9542
In epoch:010|batch:0020, train_loss:0.121861, train_ap:0.8741, train_acc:0.9844, train_auc:0.9835
In epoch:010|batch:0030, train_loss:0.124020, train_ap:0.8828, train_acc:0.9844, train_auc:0.9318
In epoch:010|batch:0000, val_loss:0.001044, val_ap:0.8116, val_acc:0.9688, val_auc:0.8803
In epoch:011|batch:0000, train_loss:0.172251, train_ap:0.6289, train_acc:0.9609, train_auc:0.8329
In epoch:011|batch:0010, train_loss:0.133342, train_ap:0.8538, train_acc:0.9688, train_auc:0.9216
In epoch:011|batch:0020, train_loss:0.116551, train_ap:0.8937, train_acc:0.9844, train_auc:0.9526
In epoch:011|batch:0030, train_loss:0.109742, train_ap:0.9379, train_acc:0.9922, train_auc:0.9965
In epoch:011|batch:0000, val_loss:0.001137, val_ap:0.7421, val_acc:0.9688, val_auc:0.8912
In epoch:012|batch:0000, train_loss:0.054639, train_ap:0.9731, train_acc:0.9844, train_auc:0.9953
In epoch:012|batch:0010, train_loss:0.126477, train_ap:1.0000, train_acc:1.0000, train_auc:1.0000
In epoch:012|batch:0020, train_loss:0.114685, train_ap:0.8866, train_acc:0.9688, train_auc:0.9104
In epoch:012|batch:0030, train_loss:0.121295, train_ap:0.7305, train_acc:0.9609, train_auc:0.8866
In epoch:012|batch:0000, val_loss:0.001156, val_ap:0.8467, val_acc:0.9609, val_auc:0.9342
In epoch:013|batch:0000, train_loss:0.205368, train_ap:0.7007, train_acc:0.9531, train_auc:0.7987
In epoch:013|batch:0010, train_loss:0.124238, train_ap:0.8405, train_acc:0.9531, train_auc:0.9569
In epoch:013|batch:0020, train_loss:0.123804, train_ap:0.9137, train_acc:0.9922, train_auc:0.9466
In epoch:013|batch:0030, train_loss:0.126264, train_ap:0.7042, train_acc:0.9531, train_auc:0.9161
In epoch:013|batch:0000, val_loss:0.001631, val_ap:0.7679, val_acc:0.9531, val_auc:0.8934
In epoch:014|batch:0000, train_loss:0.146298, train_ap:0.7660, train_acc:0.9609, train_auc:0.9075
In epoch:014|batch:0010, train_loss:0.113573, train_ap:0.9482, train_acc:0.9609, train_auc:0.9860
In epoch:014|batch:0020, train_loss:0.107801, train_ap:0.8614, train_acc:0.9766, train_auc:0.9080
In epoch:014|batch:0030, train_loss:0.101685, train_ap:0.9159, train_acc:0.9922, train_auc:0.9739
In epoch:014|batch:0000, val_loss:0.000582, val_ap:0.9253, val_acc:0.9844, val_auc:0.9943
Best val_loss is: 0.0008376
In test batch:0000
In test batch:0010
In test batch:0020
NN out of fold AP is: 0.8381824519875147
test AUC:0.9387956667290458
test f1:0.9169280888030887
test AP:0.8575388531957369
